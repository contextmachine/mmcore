# This file was generated based on ".graphqlconfig". Do not edit manually.

schema {
    query: query_root
    mutation: mutation_root
    subscription: subscription_root
}

"whether this query should be cached (Hasura Cloud only)"
directive @cached(
    "refresh the cache entry"
    refresh: Boolean! = false,
    "measured in seconds"
    ttl: Int! = 60
) on QUERY

"mutation root"
type mutation_root {
    "delete data from the table: \"test_json_object\""
    delete_test_json_object(
        "filter the rows which have to be deleted"
        where: test_json_object_bool_exp!
    ): test_json_object_mutation_response
    "delete single row from the table: \"test_json_object\""
    delete_test_json_object_by_pk(timestamp: timestamptz!, uuid: uuid!): test_json_object
    "delete data from the table: \"test_table\""
    delete_test_table(
        "filter the rows which have to be deleted"
        where: test_table_bool_exp!
    ): test_table_mutation_response
    "delete single row from the table: \"test_table\""
    delete_test_table_by_pk(name: name!, timestamp: timestamptz!, uuid: uuid!): test_table
    "insert data into the table: \"test_json_object\""
    insert_test_json_object(
        "the rows to be inserted"
        objects: [test_json_object_insert_input!]!,
        "upsert condition"
        on_conflict: test_json_object_on_conflict
    ): test_json_object_mutation_response
    "insert a single row into the table: \"test_json_object\""
    insert_test_json_object_one(
        "the row to be inserted"
        object: test_json_object_insert_input!,
        "upsert condition"
        on_conflict: test_json_object_on_conflict
    ): test_json_object
    "insert data into the table: \"test_table\""
    insert_test_table(
        "the rows to be inserted"
        objects: [test_table_insert_input!]!,
        "upsert condition"
        on_conflict: test_table_on_conflict
    ): test_table_mutation_response
    "insert a single row into the table: \"test_table\""
    insert_test_table_one(
        "the row to be inserted"
        object: test_table_insert_input!,
        "upsert condition"
        on_conflict: test_table_on_conflict
    ): test_table
    "update data of the table: \"test_json_object\""
    update_test_json_object(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: test_json_object_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: test_json_object_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: test_json_object_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: test_json_object_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: test_json_object_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: test_json_object_set_input,
        "filter the rows which have to be updated"
        where: test_json_object_bool_exp!
    ): test_json_object_mutation_response
    "update single row of the table: \"test_json_object\""
    update_test_json_object_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: test_json_object_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: test_json_object_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: test_json_object_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: test_json_object_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: test_json_object_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: test_json_object_set_input,
        pk_columns: test_json_object_pk_columns_input!
    ): test_json_object
    "update multiples rows of table: \"test_json_object\""
    update_test_json_object_many(
        "updates to execute, in order"
        updates: [test_json_object_updates!]!
    ): [test_json_object_mutation_response]
    "update data of the table: \"test_table\""
    update_test_table(
        "sets the columns of the filtered rows to the given values"
        _set: test_table_set_input,
        "filter the rows which have to be updated"
        where: test_table_bool_exp!
    ): test_table_mutation_response
    "update single row of the table: \"test_table\""
    update_test_table_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: test_table_set_input,
        pk_columns: test_table_pk_columns_input!
    ): test_table
    "update multiples rows of table: \"test_table\""
    update_test_table_many(
        "updates to execute, in order"
        updates: [test_table_updates!]!
    ): [test_table_mutation_response]
}

type query_root {
    "fetch data from the table: \"test_json_object\""
    test_json_object(
        "distinct select on columns"
        distinct_on: [test_json_object_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [test_json_object_order_by!],
        "filter the rows returned"
        where: test_json_object_bool_exp
    ): [test_json_object!]!
    "fetch aggregated fields from the table: \"test_json_object\""
    test_json_object_aggregate(
        "distinct select on columns"
        distinct_on: [test_json_object_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [test_json_object_order_by!],
        "filter the rows returned"
        where: test_json_object_bool_exp
    ): test_json_object_aggregate!
    "fetch data from the table: \"test_json_object\" using primary key columns"
    test_json_object_by_pk(timestamp: timestamptz!, uuid: uuid!): test_json_object
    "fetch data from the table: \"test_table\""
    test_table(
        "distinct select on columns"
        distinct_on: [test_table_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [test_table_order_by!],
        "filter the rows returned"
        where: test_table_bool_exp
    ): [test_table!]!
    "fetch aggregated fields from the table: \"test_table\""
    test_table_aggregate(
        "distinct select on columns"
        distinct_on: [test_table_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [test_table_order_by!],
        "filter the rows returned"
        where: test_table_bool_exp
    ): test_table_aggregate!
    "fetch data from the table: \"test_table\" using primary key columns"
    test_table_by_pk(name: name!, timestamp: timestamptz!, uuid: uuid!): test_table
}

type subscription_root {
    "fetch data from the table: \"test_json_object\""
    test_json_object(
        "distinct select on columns"
        distinct_on: [test_json_object_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [test_json_object_order_by!],
        "filter the rows returned"
        where: test_json_object_bool_exp
    ): [test_json_object!]!
    "fetch aggregated fields from the table: \"test_json_object\""
    test_json_object_aggregate(
        "distinct select on columns"
        distinct_on: [test_json_object_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [test_json_object_order_by!],
        "filter the rows returned"
        where: test_json_object_bool_exp
    ): test_json_object_aggregate!
    "fetch data from the table: \"test_json_object\" using primary key columns"
    test_json_object_by_pk(timestamp: timestamptz!, uuid: uuid!): test_json_object
    "fetch data from the table in a streaming manner: \"test_json_object\""
    test_json_object_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [test_json_object_stream_cursor_input]!,
        "filter the rows returned"
        where: test_json_object_bool_exp
    ): [test_json_object!]!
    "fetch data from the table: \"test_table\""
    test_table(
        "distinct select on columns"
        distinct_on: [test_table_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [test_table_order_by!],
        "filter the rows returned"
        where: test_table_bool_exp
    ): [test_table!]!
    "fetch aggregated fields from the table: \"test_table\""
    test_table_aggregate(
        "distinct select on columns"
        distinct_on: [test_table_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [test_table_order_by!],
        "filter the rows returned"
        where: test_table_bool_exp
    ): test_table_aggregate!
    "fetch data from the table: \"test_table\" using primary key columns"
    test_table_by_pk(name: name!, timestamp: timestamptz!, uuid: uuid!): test_table
    "fetch data from the table in a streaming manner: \"test_table\""
    test_table_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [test_table_stream_cursor_input]!,
        "filter the rows returned"
        where: test_table_bool_exp
    ): [test_table!]!
}

"columns and relationships of \"test_json_object\""
type test_json_object {
    data(
        "JSON select path"
        path: String
    ): jsonb!
    name: name
    timestamp: timestamptz!
    uuid: uuid!
}

"aggregated selection of \"test_json_object\""
type test_json_object_aggregate {
    aggregate: test_json_object_aggregate_fields
    nodes: [test_json_object!]!
}

"aggregate fields of \"test_json_object\""
type test_json_object_aggregate_fields {
    count(columns: [test_json_object_select_column!], distinct: Boolean): Int!
    max: test_json_object_max_fields
    min: test_json_object_min_fields
}

"aggregate max on columns"
type test_json_object_max_fields {
    timestamp: timestamptz
    uuid: uuid
}

"aggregate min on columns"
type test_json_object_min_fields {
    timestamp: timestamptz
    uuid: uuid
}

"response of any mutation on the table \"test_json_object\""
type test_json_object_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [test_json_object!]!
}

"Test table (for backends)"
type test_table {
    data: jsonpath
    name: name!
    timestamp: timestamptz!
    uuid: uuid!
}

"aggregated selection of \"test_table\""
type test_table_aggregate {
    aggregate: test_table_aggregate_fields
    nodes: [test_table!]!
}

"aggregate fields of \"test_table\""
type test_table_aggregate_fields {
    count(columns: [test_table_select_column!], distinct: Boolean): Int!
    max: test_table_max_fields
    min: test_table_min_fields
}

"aggregate max on columns"
type test_table_max_fields {
    timestamp: timestamptz
    uuid: uuid
}

"aggregate min on columns"
type test_table_min_fields {
    timestamp: timestamptz
    uuid: uuid
}

"response of any mutation on the table \"test_table\""
type test_table_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [test_table!]!
}

"ordering argument of a cursor"
enum cursor_ordering {
    "ascending ordering of the cursor"
    ASC
    "descending ordering of the cursor"
    DESC
}

"column ordering options"
enum order_by {
    "in ascending order, nulls last"
    asc
    "in ascending order, nulls first"
    asc_nulls_first
    "in ascending order, nulls last"
    asc_nulls_last
    "in descending order, nulls first"
    desc
    "in descending order, nulls first"
    desc_nulls_first
    "in descending order, nulls last"
    desc_nulls_last
}

"unique or primary key constraints on table \"test_json_object\""
enum test_json_object_constraint {
    "unique or primary key constraint on columns \"timestamp\", \"uuid\""
    test_json_object_pkey
    "unique or primary key constraint on columns \"uuid\""
    test_json_object_uuid_key
}

"select columns of table \"test_json_object\""
enum test_json_object_select_column {
    "column name"
    data
    "column name"
    name
    "column name"
    timestamp
    "column name"
    uuid
}

"update columns of table \"test_json_object\""
enum test_json_object_update_column {
    "column name"
    data
    "column name"
    name
    "column name"
    timestamp
    "column name"
    uuid
}

"unique or primary key constraints on table \"test_table\""
enum test_table_constraint {
    "unique or primary key constraint on columns \"name\", \"timestamp\", \"uuid\""
    test_table_pkey
    "unique or primary key constraint on columns \"uuid\""
    test_table_uuid_key
}

"select columns of table \"test_table\""
enum test_table_select_column {
    "column name"
    data
    "column name"
    name
    "column name"
    timestamp
    "column name"
    uuid
}

"update columns of table \"test_table\""
enum test_table_update_column {
    "column name"
    data
    "column name"
    name
    "column name"
    timestamp
    "column name"
    uuid
}

scalar jsonb

scalar jsonpath

scalar name

scalar timestamptz

scalar uuid

"Boolean expression to compare columns of type \"String\". All fields are combined with logical 'AND'."
input String_comparison_exp {
    _eq: String
    _gt: String
    _gte: String
    "does the column match the given case-insensitive pattern"
    _ilike: String
    _in: [String!]
    "does the column match the given POSIX regular expression, case insensitive"
    _iregex: String
    _is_null: Boolean
    "does the column match the given pattern"
    _like: String
    _lt: String
    _lte: String
    _neq: String
    "does the column NOT match the given case-insensitive pattern"
    _nilike: String
    _nin: [String!]
    "does the column NOT match the given POSIX regular expression, case insensitive"
    _niregex: String
    "does the column NOT match the given pattern"
    _nlike: String
    "does the column NOT match the given POSIX regular expression, case sensitive"
    _nregex: String
    "does the column NOT match the given SQL regular expression"
    _nsimilar: String
    "does the column match the given POSIX regular expression, case sensitive"
    _regex: String
    "does the column match the given SQL regular expression"
    _similar: String
}

input jsonb_cast_exp {
    String: String_comparison_exp
}

"Boolean expression to compare columns of type \"jsonb\". All fields are combined with logical 'AND'."
input jsonb_comparison_exp {
    _cast: jsonb_cast_exp
    "is the column contained in the given json value"
    _contained_in: jsonb
    "does the column contain the given json value at the top level"
    _contains: jsonb
    _eq: jsonb
    _gt: jsonb
    _gte: jsonb
    "does the string exist as a top-level key in the column"
    _has_key: String
    "do all of these strings exist as top-level keys in the column"
    _has_keys_all: [String!]
    "do any of these strings exist as top-level keys in the column"
    _has_keys_any: [String!]
    _in: [jsonb!]
    _is_null: Boolean
    _lt: jsonb
    _lte: jsonb
    _neq: jsonb
    _nin: [jsonb!]
}

"Boolean expression to compare columns of type \"jsonpath\". All fields are combined with logical 'AND'."
input jsonpath_comparison_exp {
    _eq: jsonpath
    _gt: jsonpath
    _gte: jsonpath
    _in: [jsonpath!]
    _is_null: Boolean
    _lt: jsonpath
    _lte: jsonpath
    _neq: jsonpath
    _nin: [jsonpath!]
}

"Boolean expression to compare columns of type \"name\". All fields are combined with logical 'AND'."
input name_comparison_exp {
    _eq: name
    _gt: name
    _gte: name
    _in: [name!]
    _is_null: Boolean
    _lt: name
    _lte: name
    _neq: name
    _nin: [name!]
}

"append existing jsonb value of filtered columns with new jsonb value"
input test_json_object_append_input {
    data: jsonb
}

"Boolean expression to filter rows from the table \"test_json_object\". All fields are combined with a logical 'AND'."
input test_json_object_bool_exp {
    _and: [test_json_object_bool_exp!]
    _not: test_json_object_bool_exp
    _or: [test_json_object_bool_exp!]
    data: jsonb_comparison_exp
    name: name_comparison_exp
    timestamp: timestamptz_comparison_exp
    uuid: uuid_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input test_json_object_delete_at_path_input {
    data: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input test_json_object_delete_elem_input {
    data: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input test_json_object_delete_key_input {
    data: String
}

"input type for inserting data into table \"test_json_object\""
input test_json_object_insert_input {
    data: jsonb
    name: name
    timestamp: timestamptz
    uuid: uuid
}

"on_conflict condition type for table \"test_json_object\""
input test_json_object_on_conflict {
    constraint: test_json_object_constraint!
    update_columns: [test_json_object_update_column!]! = []
    where: test_json_object_bool_exp
}

"Ordering options when selecting data from \"test_json_object\"."
input test_json_object_order_by {
    data: order_by
    name: order_by
    timestamp: order_by
    uuid: order_by
}

"primary key columns input for table: test_json_object"
input test_json_object_pk_columns_input {
    timestamp: timestamptz!
    uuid: uuid!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input test_json_object_prepend_input {
    data: jsonb
}

"input type for updating data in table \"test_json_object\""
input test_json_object_set_input {
    data: jsonb
    name: name
    timestamp: timestamptz
    uuid: uuid
}

"Streaming cursor of the table \"test_json_object\""
input test_json_object_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: test_json_object_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input test_json_object_stream_cursor_value_input {
    data: jsonb
    name: name
    timestamp: timestamptz
    uuid: uuid
}

input test_json_object_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: test_json_object_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: test_json_object_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: test_json_object_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: test_json_object_delete_key_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: test_json_object_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: test_json_object_set_input
    "filter the rows which have to be updated"
    where: test_json_object_bool_exp!
}

"Boolean expression to filter rows from the table \"test_table\". All fields are combined with a logical 'AND'."
input test_table_bool_exp {
    _and: [test_table_bool_exp!]
    _not: test_table_bool_exp
    _or: [test_table_bool_exp!]
    data: jsonpath_comparison_exp
    name: name_comparison_exp
    timestamp: timestamptz_comparison_exp
    uuid: uuid_comparison_exp
}

"input type for inserting data into table \"test_table\""
input test_table_insert_input {
    data: jsonpath
    name: name
    timestamp: timestamptz
    uuid: uuid
}

"on_conflict condition type for table \"test_table\""
input test_table_on_conflict {
    constraint: test_table_constraint!
    update_columns: [test_table_update_column!]! = []
    where: test_table_bool_exp
}

"Ordering options when selecting data from \"test_table\"."
input test_table_order_by {
    data: order_by
    name: order_by
    timestamp: order_by
    uuid: order_by
}

"primary key columns input for table: test_table"
input test_table_pk_columns_input {
    name: name!
    timestamp: timestamptz!
    uuid: uuid!
}

"input type for updating data in table \"test_table\""
input test_table_set_input {
    data: jsonpath
    name: name
    timestamp: timestamptz
    uuid: uuid
}

"Streaming cursor of the table \"test_table\""
input test_table_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: test_table_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input test_table_stream_cursor_value_input {
    data: jsonpath
    name: name
    timestamp: timestamptz
    uuid: uuid
}

input test_table_updates {
    "sets the columns of the filtered rows to the given values"
    _set: test_table_set_input
    "filter the rows which have to be updated"
    where: test_table_bool_exp!
}

"Boolean expression to compare columns of type \"timestamptz\". All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
    _eq: timestamptz
    _gt: timestamptz
    _gte: timestamptz
    _in: [timestamptz!]
    _is_null: Boolean
    _lt: timestamptz
    _lte: timestamptz
    _neq: timestamptz
    _nin: [timestamptz!]
}

"Boolean expression to compare columns of type \"uuid\". All fields are combined with logical 'AND'."
input uuid_comparison_exp {
    _eq: uuid
    _gt: uuid
    _gte: uuid
    _in: [uuid!]
    _is_null: Boolean
    _lt: uuid
    _lte: uuid
    _neq: uuid
    _nin: [uuid!]
}
