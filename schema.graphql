# This file was generated based on ".graphqlconfig". Do not edit manually.

schema {
    query: query_root
    mutation: mutation_root
    subscription: subscription_root
}

"whether this query should be cached (Hasura Cloud only)"
directive @cached(
    "refresh the cache entry"
    refresh: Boolean! = false,
    "measured in seconds"
    ttl: Int! = 60
) on QUERY

"A union of all types that use the @key directive"
union _Entity = lht_triangles_connectors | lht_triangles_contours | lht_triangles_floors | mfb_params_base_points | mfb_params_parts | survey_ceiling

type _Service {
    "SDL representation of schema"
    sdl: String!
}

"columns and relationships of \"lht_triangles.connectors\""
type lht_triangles_connectors {
    "An array relationship"
    contours(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "An aggregate relationship"
    contours_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): lht_triangles_contours_aggregate!
    from: String
    name: String!
    offset: numeric
    production: String
    type: String
}

"aggregated selection of \"lht_triangles.connectors\""
type lht_triangles_connectors_aggregate {
    aggregate: lht_triangles_connectors_aggregate_fields
    nodes: [lht_triangles_connectors!]!
}

"aggregate fields of \"lht_triangles.connectors\""
type lht_triangles_connectors_aggregate_fields {
    avg: lht_triangles_connectors_avg_fields
    count(columns: [lht_triangles_connectors_select_column!], distinct: Boolean): Int!
    max: lht_triangles_connectors_max_fields
    min: lht_triangles_connectors_min_fields
    stddev: lht_triangles_connectors_stddev_fields
    stddev_pop: lht_triangles_connectors_stddev_pop_fields
    stddev_samp: lht_triangles_connectors_stddev_samp_fields
    sum: lht_triangles_connectors_sum_fields
    var_pop: lht_triangles_connectors_var_pop_fields
    var_samp: lht_triangles_connectors_var_samp_fields
    variance: lht_triangles_connectors_variance_fields
}

"aggregate avg on columns"
type lht_triangles_connectors_avg_fields {
    offset: Float
}

"aggregate max on columns"
type lht_triangles_connectors_max_fields {
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

"aggregate min on columns"
type lht_triangles_connectors_min_fields {
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

"response of any mutation on the table \"lht_triangles.connectors\""
type lht_triangles_connectors_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_triangles_connectors!]!
}

"aggregate stddev on columns"
type lht_triangles_connectors_stddev_fields {
    offset: Float
}

"aggregate stddev_pop on columns"
type lht_triangles_connectors_stddev_pop_fields {
    offset: Float
}

"aggregate stddev_samp on columns"
type lht_triangles_connectors_stddev_samp_fields {
    offset: Float
}

"aggregate sum on columns"
type lht_triangles_connectors_sum_fields {
    offset: numeric
}

"aggregate var_pop on columns"
type lht_triangles_connectors_var_pop_fields {
    offset: Float
}

"aggregate var_samp on columns"
type lht_triangles_connectors_var_samp_fields {
    offset: Float
}

"aggregate variance on columns"
type lht_triangles_connectors_variance_fields {
    offset: Float
}

"columns and relationships of \"lht_triangles.contours\""
type lht_triangles_contours {
    "An object relationship"
    connector: lht_triangles_connectors
    curve(
        "JSON select path"
        path: String
    ): jsonb
    detail: name
    floor: lht_triangles_floors_enum
    "An object relationship"
    floorByFloor: lht_triangles_floors
    uuid: uuid!
}

"aggregated selection of \"lht_triangles.contours\""
type lht_triangles_contours_aggregate {
    aggregate: lht_triangles_contours_aggregate_fields
    nodes: [lht_triangles_contours!]!
}

"aggregate fields of \"lht_triangles.contours\""
type lht_triangles_contours_aggregate_fields {
    count(columns: [lht_triangles_contours_select_column!], distinct: Boolean): Int!
    max: lht_triangles_contours_max_fields
    min: lht_triangles_contours_min_fields
}

"aggregate max on columns"
type lht_triangles_contours_max_fields {
    uuid: uuid
}

"aggregate min on columns"
type lht_triangles_contours_min_fields {
    uuid: uuid
}

"response of any mutation on the table \"lht_triangles.contours\""
type lht_triangles_contours_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_triangles_contours!]!
}

"columns and relationships of \"lht_triangles.floors\""
type lht_triangles_floors {
    comment: String
    "An array relationship"
    entities(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "An aggregate relationship"
    entities_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): lht_triangles_contours_aggregate!
    value: String!
}

"aggregated selection of \"lht_triangles.floors\""
type lht_triangles_floors_aggregate {
    aggregate: lht_triangles_floors_aggregate_fields
    nodes: [lht_triangles_floors!]!
}

"aggregate fields of \"lht_triangles.floors\""
type lht_triangles_floors_aggregate_fields {
    count(columns: [lht_triangles_floors_select_column!], distinct: Boolean): Int!
    max: lht_triangles_floors_max_fields
    min: lht_triangles_floors_min_fields
}

"aggregate max on columns"
type lht_triangles_floors_max_fields {
    comment: String
    value: String
}

"aggregate min on columns"
type lht_triangles_floors_min_fields {
    comment: String
    value: String
}

"response of any mutation on the table \"lht_triangles.floors\""
type lht_triangles_floors_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_triangles_floors!]!
}

"columns and relationships of \"lht_triangles.transforms\""
type lht_triangles_transforms {
    name: String!
    value(
        "JSON select path"
        path: String
    ): jsonb!
}

"aggregated selection of \"lht_triangles.transforms\""
type lht_triangles_transforms_aggregate {
    aggregate: lht_triangles_transforms_aggregate_fields
    nodes: [lht_triangles_transforms!]!
}

"aggregate fields of \"lht_triangles.transforms\""
type lht_triangles_transforms_aggregate_fields {
    count(columns: [lht_triangles_transforms_select_column!], distinct: Boolean): Int!
    max: lht_triangles_transforms_max_fields
    min: lht_triangles_transforms_min_fields
}

"aggregate max on columns"
type lht_triangles_transforms_max_fields {
    name: String
}

"aggregate min on columns"
type lht_triangles_transforms_min_fields {
    name: String
}

"response of any mutation on the table \"lht_triangles.transforms\""
type lht_triangles_transforms_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_triangles_transforms!]!
}

"columns and relationships of \"mfb_params.base_points\""
type mfb_params_base_points {
    id: Int!
    name: String!
    "An object relationship"
    part: mfb_params_parts!
    part_name: mfb_params_parts_enum!
    update_at: timestamp
    x: numeric
    y: numeric
    z: numeric
}

"aggregated selection of \"mfb_params.base_points\""
type mfb_params_base_points_aggregate {
    aggregate: mfb_params_base_points_aggregate_fields
    nodes: [mfb_params_base_points!]!
}

"aggregate fields of \"mfb_params.base_points\""
type mfb_params_base_points_aggregate_fields {
    avg: mfb_params_base_points_avg_fields
    count(columns: [mfb_params_base_points_select_column!], distinct: Boolean): Int!
    max: mfb_params_base_points_max_fields
    min: mfb_params_base_points_min_fields
    stddev: mfb_params_base_points_stddev_fields
    stddev_pop: mfb_params_base_points_stddev_pop_fields
    stddev_samp: mfb_params_base_points_stddev_samp_fields
    sum: mfb_params_base_points_sum_fields
    var_pop: mfb_params_base_points_var_pop_fields
    var_samp: mfb_params_base_points_var_samp_fields
    variance: mfb_params_base_points_variance_fields
}

"aggregate avg on columns"
type mfb_params_base_points_avg_fields {
    id: Float
    x: Float
    y: Float
    z: Float
}

"aggregate max on columns"
type mfb_params_base_points_max_fields {
    id: Int
    name: String
    update_at: timestamp
    x: numeric
    y: numeric
    z: numeric
}

"aggregate min on columns"
type mfb_params_base_points_min_fields {
    id: Int
    name: String
    update_at: timestamp
    x: numeric
    y: numeric
    z: numeric
}

"response of any mutation on the table \"mfb_params.base_points\""
type mfb_params_base_points_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [mfb_params_base_points!]!
}

"aggregate stddev on columns"
type mfb_params_base_points_stddev_fields {
    id: Float
    x: Float
    y: Float
    z: Float
}

"aggregate stddev_pop on columns"
type mfb_params_base_points_stddev_pop_fields {
    id: Float
    x: Float
    y: Float
    z: Float
}

"aggregate stddev_samp on columns"
type mfb_params_base_points_stddev_samp_fields {
    id: Float
    x: Float
    y: Float
    z: Float
}

"aggregate sum on columns"
type mfb_params_base_points_sum_fields {
    id: Int
    x: numeric
    y: numeric
    z: numeric
}

"aggregate var_pop on columns"
type mfb_params_base_points_var_pop_fields {
    id: Float
    x: Float
    y: Float
    z: Float
}

"aggregate var_samp on columns"
type mfb_params_base_points_var_samp_fields {
    id: Float
    x: Float
    y: Float
    z: Float
}

"aggregate variance on columns"
type mfb_params_base_points_variance_fields {
    id: Float
    x: Float
    y: Float
    z: Float
}

"columns and relationships of \"mfb_params.parts\""
type mfb_params_parts {
    "An array relationship"
    base_points(
        "distinct select on columns"
        distinct_on: [mfb_params_base_points_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_base_points_order_by!],
        "filter the rows returned"
        where: mfb_params_base_points_bool_exp
    ): [mfb_params_base_points!]!
    "An aggregate relationship"
    base_points_aggregate(
        "distinct select on columns"
        distinct_on: [mfb_params_base_points_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_base_points_order_by!],
        "filter the rows returned"
        where: mfb_params_base_points_bool_exp
    ): mfb_params_base_points_aggregate!
    comment: String
    name: String!
}

"aggregated selection of \"mfb_params.parts\""
type mfb_params_parts_aggregate {
    aggregate: mfb_params_parts_aggregate_fields
    nodes: [mfb_params_parts!]!
}

"aggregate fields of \"mfb_params.parts\""
type mfb_params_parts_aggregate_fields {
    count(columns: [mfb_params_parts_select_column!], distinct: Boolean): Int!
    max: mfb_params_parts_max_fields
    min: mfb_params_parts_min_fields
}

"aggregate max on columns"
type mfb_params_parts_max_fields {
    comment: String
    name: String
}

"aggregate min on columns"
type mfb_params_parts_min_fields {
    comment: String
    name: String
}

"response of any mutation on the table \"mfb_params.parts\""
type mfb_params_parts_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [mfb_params_parts!]!
}

"mutation root"
type mutation_root {
    "delete data from the table: \"lht_triangles.connectors\""
    delete_lht_triangles_connectors(
        "filter the rows which have to be deleted"
        where: lht_triangles_connectors_bool_exp!
    ): lht_triangles_connectors_mutation_response
    "delete single row from the table: \"lht_triangles.connectors\""
    delete_lht_triangles_connectors_by_pk(name: String!): lht_triangles_connectors
    "delete data from the table: \"lht_triangles.contours\""
    delete_lht_triangles_contours(
        "filter the rows which have to be deleted"
        where: lht_triangles_contours_bool_exp!
    ): lht_triangles_contours_mutation_response
    "delete single row from the table: \"lht_triangles.contours\""
    delete_lht_triangles_contours_by_pk(uuid: uuid!): lht_triangles_contours
    "delete data from the table: \"lht_triangles.floors\""
    delete_lht_triangles_floors(
        "filter the rows which have to be deleted"
        where: lht_triangles_floors_bool_exp!
    ): lht_triangles_floors_mutation_response
    "delete single row from the table: \"lht_triangles.floors\""
    delete_lht_triangles_floors_by_pk(value: String!): lht_triangles_floors
    "delete data from the table: \"lht_triangles.transforms\""
    delete_lht_triangles_transforms(
        "filter the rows which have to be deleted"
        where: lht_triangles_transforms_bool_exp!
    ): lht_triangles_transforms_mutation_response
    "delete single row from the table: \"lht_triangles.transforms\""
    delete_lht_triangles_transforms_by_pk(name: String!): lht_triangles_transforms
    "delete data from the table: \"mfb_params.base_points\""
    delete_mfb_params_base_points(
        "filter the rows which have to be deleted"
        where: mfb_params_base_points_bool_exp!
    ): mfb_params_base_points_mutation_response
    "delete single row from the table: \"mfb_params.base_points\""
    delete_mfb_params_base_points_by_pk(name: String!, part_name: mfb_params_parts_enum!): mfb_params_base_points
    "delete data from the table: \"mfb_params.parts\""
    delete_mfb_params_parts(
        "filter the rows which have to be deleted"
        where: mfb_params_parts_bool_exp!
    ): mfb_params_parts_mutation_response
    "delete single row from the table: \"mfb_params.parts\""
    delete_mfb_params_parts_by_pk(name: String!): mfb_params_parts
    "delete data from the table: \"objects_hub\""
    delete_objects_hub(
        "filter the rows which have to be deleted"
        where: objects_hub_bool_exp!
    ): objects_hub_mutation_response
    "delete single row from the table: \"objects_hub\""
    delete_objects_hub_by_pk(uuid: uuid!): objects_hub
    "delete data from the table: \"platform.hosts\""
    delete_platform_hosts(
        "filter the rows which have to be deleted"
        where: platform_hosts_bool_exp!
    ): platform_hosts_mutation_response
    "delete single row from the table: \"platform.hosts\""
    delete_platform_hosts_by_pk(name: String!): platform_hosts
    "delete data from the table: \"platform.service\""
    delete_platform_service(
        "filter the rows which have to be deleted"
        where: platform_service_bool_exp!
    ): platform_service_mutation_response
    "delete data from the table: \"platform.service_attributes\""
    delete_platform_service_attributes(
        "filter the rows which have to be deleted"
        where: platform_service_attributes_bool_exp!
    ): platform_service_attributes_mutation_response
    "delete single row from the table: \"platform.service_attributes\""
    delete_platform_service_attributes_by_pk(port: Int!): platform_service_attributes
    "delete single row from the table: \"platform.service\""
    delete_platform_service_by_pk(value: String!): platform_service
    "delete data from the table: \"platform.services\""
    delete_platform_services(
        "filter the rows which have to be deleted"
        where: platform_services_bool_exp!
    ): platform_services_mutation_response
    "delete data from the table: \"platform.subscribes\""
    delete_platform_subscribes(
        "filter the rows which have to be deleted"
        where: platform_subscribes_bool_exp!
    ): platform_subscribes_mutation_response
    "delete single row from the table: \"platform.subscribes\""
    delete_platform_subscribes_by_pk(id: Int!): platform_subscribes
    "delete data from the table: \"platform.topics\""
    delete_platform_topics(
        "filter the rows which have to be deleted"
        where: platform_topics_bool_exp!
    ): platform_topics_mutation_response
    "delete single row from the table: \"platform.topics\""
    delete_platform_topics_by_pk(value: String!): platform_topics
    "delete data from the table: \"survey.ceiling\""
    delete_survey_ceiling(
        "filter the rows which have to be deleted"
        where: survey_ceiling_bool_exp!
    ): survey_ceiling_mutation_response
    "delete single row from the table: \"survey.ceiling\""
    delete_survey_ceiling_by_pk(id: Int!): survey_ceiling
    "delete data from the table: \"threejs.types\""
    delete_threejs_types(
        "filter the rows which have to be deleted"
        where: threejs_types_bool_exp!
    ): threejs_types_mutation_response
    "delete single row from the table: \"threejs.types\""
    delete_threejs_types_by_pk(value: String!): threejs_types
    "insert data into the table: \"lht_triangles.connectors\""
    insert_lht_triangles_connectors(
        "the rows to be inserted"
        objects: [lht_triangles_connectors_insert_input!]!,
        "upsert condition"
        on_conflict: lht_triangles_connectors_on_conflict
    ): lht_triangles_connectors_mutation_response
    "insert a single row into the table: \"lht_triangles.connectors\""
    insert_lht_triangles_connectors_one(
        "the row to be inserted"
        object: lht_triangles_connectors_insert_input!,
        "upsert condition"
        on_conflict: lht_triangles_connectors_on_conflict
    ): lht_triangles_connectors
    "insert data into the table: \"lht_triangles.contours\""
    insert_lht_triangles_contours(
        "the rows to be inserted"
        objects: [lht_triangles_contours_insert_input!]!,
        "upsert condition"
        on_conflict: lht_triangles_contours_on_conflict
    ): lht_triangles_contours_mutation_response
    "insert a single row into the table: \"lht_triangles.contours\""
    insert_lht_triangles_contours_one(
        "the row to be inserted"
        object: lht_triangles_contours_insert_input!,
        "upsert condition"
        on_conflict: lht_triangles_contours_on_conflict
    ): lht_triangles_contours
    "insert data into the table: \"lht_triangles.floors\""
    insert_lht_triangles_floors(
        "the rows to be inserted"
        objects: [lht_triangles_floors_insert_input!]!,
        "upsert condition"
        on_conflict: lht_triangles_floors_on_conflict
    ): lht_triangles_floors_mutation_response
    "insert a single row into the table: \"lht_triangles.floors\""
    insert_lht_triangles_floors_one(
        "the row to be inserted"
        object: lht_triangles_floors_insert_input!,
        "upsert condition"
        on_conflict: lht_triangles_floors_on_conflict
    ): lht_triangles_floors
    "insert data into the table: \"lht_triangles.transforms\""
    insert_lht_triangles_transforms(
        "the rows to be inserted"
        objects: [lht_triangles_transforms_insert_input!]!,
        "upsert condition"
        on_conflict: lht_triangles_transforms_on_conflict
    ): lht_triangles_transforms_mutation_response
    "insert a single row into the table: \"lht_triangles.transforms\""
    insert_lht_triangles_transforms_one(
        "the row to be inserted"
        object: lht_triangles_transforms_insert_input!,
        "upsert condition"
        on_conflict: lht_triangles_transforms_on_conflict
    ): lht_triangles_transforms
    "insert data into the table: \"mfb_params.base_points\""
    insert_mfb_params_base_points(
        "the rows to be inserted"
        objects: [mfb_params_base_points_insert_input!]!,
        "upsert condition"
        on_conflict: mfb_params_base_points_on_conflict
    ): mfb_params_base_points_mutation_response
    "insert a single row into the table: \"mfb_params.base_points\""
    insert_mfb_params_base_points_one(
        "the row to be inserted"
        object: mfb_params_base_points_insert_input!,
        "upsert condition"
        on_conflict: mfb_params_base_points_on_conflict
    ): mfb_params_base_points
    "insert data into the table: \"mfb_params.parts\""
    insert_mfb_params_parts(
        "the rows to be inserted"
        objects: [mfb_params_parts_insert_input!]!,
        "upsert condition"
        on_conflict: mfb_params_parts_on_conflict
    ): mfb_params_parts_mutation_response
    "insert a single row into the table: \"mfb_params.parts\""
    insert_mfb_params_parts_one(
        "the row to be inserted"
        object: mfb_params_parts_insert_input!,
        "upsert condition"
        on_conflict: mfb_params_parts_on_conflict
    ): mfb_params_parts
    "insert data into the table: \"objects_hub\""
    insert_objects_hub(
        "the rows to be inserted"
        objects: [objects_hub_insert_input!]!,
        "upsert condition"
        on_conflict: objects_hub_on_conflict
    ): objects_hub_mutation_response
    "insert a single row into the table: \"objects_hub\""
    insert_objects_hub_one(
        "the row to be inserted"
        object: objects_hub_insert_input!,
        "upsert condition"
        on_conflict: objects_hub_on_conflict
    ): objects_hub
    "insert data into the table: \"platform.hosts\""
    insert_platform_hosts(
        "the rows to be inserted"
        objects: [platform_hosts_insert_input!]!,
        "upsert condition"
        on_conflict: platform_hosts_on_conflict
    ): platform_hosts_mutation_response
    "insert a single row into the table: \"platform.hosts\""
    insert_platform_hosts_one(
        "the row to be inserted"
        object: platform_hosts_insert_input!,
        "upsert condition"
        on_conflict: platform_hosts_on_conflict
    ): platform_hosts
    "insert data into the table: \"platform.service\""
    insert_platform_service(
        "the rows to be inserted"
        objects: [platform_service_insert_input!]!,
        "upsert condition"
        on_conflict: platform_service_on_conflict
    ): platform_service_mutation_response
    "insert data into the table: \"platform.service_attributes\""
    insert_platform_service_attributes(
        "the rows to be inserted"
        objects: [platform_service_attributes_insert_input!]!,
        "upsert condition"
        on_conflict: platform_service_attributes_on_conflict
    ): platform_service_attributes_mutation_response
    "insert a single row into the table: \"platform.service_attributes\""
    insert_platform_service_attributes_one(
        "the row to be inserted"
        object: platform_service_attributes_insert_input!,
        "upsert condition"
        on_conflict: platform_service_attributes_on_conflict
    ): platform_service_attributes
    "insert a single row into the table: \"platform.service\""
    insert_platform_service_one(
        "the row to be inserted"
        object: platform_service_insert_input!,
        "upsert condition"
        on_conflict: platform_service_on_conflict
    ): platform_service
    "insert data into the table: \"platform.services\""
    insert_platform_services(
        "the rows to be inserted"
        objects: [platform_services_insert_input!]!
    ): platform_services_mutation_response
    "insert a single row into the table: \"platform.services\""
    insert_platform_services_one(
        "the row to be inserted"
        object: platform_services_insert_input!
    ): platform_services
    "insert data into the table: \"platform.subscribes\""
    insert_platform_subscribes(
        "the rows to be inserted"
        objects: [platform_subscribes_insert_input!]!,
        "upsert condition"
        on_conflict: platform_subscribes_on_conflict
    ): platform_subscribes_mutation_response
    "insert a single row into the table: \"platform.subscribes\""
    insert_platform_subscribes_one(
        "the row to be inserted"
        object: platform_subscribes_insert_input!,
        "upsert condition"
        on_conflict: platform_subscribes_on_conflict
    ): platform_subscribes
    "insert data into the table: \"platform.topics\""
    insert_platform_topics(
        "the rows to be inserted"
        objects: [platform_topics_insert_input!]!,
        "upsert condition"
        on_conflict: platform_topics_on_conflict
    ): platform_topics_mutation_response
    "insert a single row into the table: \"platform.topics\""
    insert_platform_topics_one(
        "the row to be inserted"
        object: platform_topics_insert_input!,
        "upsert condition"
        on_conflict: platform_topics_on_conflict
    ): platform_topics
    "insert data into the table: \"survey.ceiling\""
    insert_survey_ceiling(
        "the rows to be inserted"
        objects: [survey_ceiling_insert_input!]!,
        "upsert condition"
        on_conflict: survey_ceiling_on_conflict
    ): survey_ceiling_mutation_response
    "insert a single row into the table: \"survey.ceiling\""
    insert_survey_ceiling_one(
        "the row to be inserted"
        object: survey_ceiling_insert_input!,
        "upsert condition"
        on_conflict: survey_ceiling_on_conflict
    ): survey_ceiling
    "insert data into the table: \"threejs.types\""
    insert_threejs_types(
        "the rows to be inserted"
        objects: [threejs_types_insert_input!]!,
        "upsert condition"
        on_conflict: threejs_types_on_conflict
    ): threejs_types_mutation_response
    "insert a single row into the table: \"threejs.types\""
    insert_threejs_types_one(
        "the row to be inserted"
        object: threejs_types_insert_input!,
        "upsert condition"
        on_conflict: threejs_types_on_conflict
    ): threejs_types
    "update data of the table: \"lht_triangles.connectors\""
    update_lht_triangles_connectors(
        "increments the numeric columns with given value of the filtered values"
        _inc: lht_triangles_connectors_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_connectors_set_input,
        "filter the rows which have to be updated"
        where: lht_triangles_connectors_bool_exp!
    ): lht_triangles_connectors_mutation_response
    "update single row of the table: \"lht_triangles.connectors\""
    update_lht_triangles_connectors_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: lht_triangles_connectors_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_connectors_set_input,
        pk_columns: lht_triangles_connectors_pk_columns_input!
    ): lht_triangles_connectors
    "update multiples rows of table: \"lht_triangles.connectors\""
    update_lht_triangles_connectors_many(
        "updates to execute, in order"
        updates: [lht_triangles_connectors_updates!]!
    ): [lht_triangles_connectors_mutation_response]
    "update data of the table: \"lht_triangles.contours\""
    update_lht_triangles_contours(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: lht_triangles_contours_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: lht_triangles_contours_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: lht_triangles_contours_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: lht_triangles_contours_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: lht_triangles_contours_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_contours_set_input,
        "filter the rows which have to be updated"
        where: lht_triangles_contours_bool_exp!
    ): lht_triangles_contours_mutation_response
    "update single row of the table: \"lht_triangles.contours\""
    update_lht_triangles_contours_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: lht_triangles_contours_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: lht_triangles_contours_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: lht_triangles_contours_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: lht_triangles_contours_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: lht_triangles_contours_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_contours_set_input,
        pk_columns: lht_triangles_contours_pk_columns_input!
    ): lht_triangles_contours
    "update multiples rows of table: \"lht_triangles.contours\""
    update_lht_triangles_contours_many(
        "updates to execute, in order"
        updates: [lht_triangles_contours_updates!]!
    ): [lht_triangles_contours_mutation_response]
    "update data of the table: \"lht_triangles.floors\""
    update_lht_triangles_floors(
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_floors_set_input,
        "filter the rows which have to be updated"
        where: lht_triangles_floors_bool_exp!
    ): lht_triangles_floors_mutation_response
    "update single row of the table: \"lht_triangles.floors\""
    update_lht_triangles_floors_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_floors_set_input,
        pk_columns: lht_triangles_floors_pk_columns_input!
    ): lht_triangles_floors
    "update multiples rows of table: \"lht_triangles.floors\""
    update_lht_triangles_floors_many(
        "updates to execute, in order"
        updates: [lht_triangles_floors_updates!]!
    ): [lht_triangles_floors_mutation_response]
    "update data of the table: \"lht_triangles.transforms\""
    update_lht_triangles_transforms(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: lht_triangles_transforms_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: lht_triangles_transforms_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: lht_triangles_transforms_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: lht_triangles_transforms_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: lht_triangles_transforms_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_transforms_set_input,
        "filter the rows which have to be updated"
        where: lht_triangles_transforms_bool_exp!
    ): lht_triangles_transforms_mutation_response
    "update single row of the table: \"lht_triangles.transforms\""
    update_lht_triangles_transforms_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: lht_triangles_transforms_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: lht_triangles_transforms_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: lht_triangles_transforms_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: lht_triangles_transforms_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: lht_triangles_transforms_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_transforms_set_input,
        pk_columns: lht_triangles_transforms_pk_columns_input!
    ): lht_triangles_transforms
    "update multiples rows of table: \"lht_triangles.transforms\""
    update_lht_triangles_transforms_many(
        "updates to execute, in order"
        updates: [lht_triangles_transforms_updates!]!
    ): [lht_triangles_transforms_mutation_response]
    "update data of the table: \"mfb_params.base_points\""
    update_mfb_params_base_points(
        "increments the numeric columns with given value of the filtered values"
        _inc: mfb_params_base_points_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: mfb_params_base_points_set_input,
        "filter the rows which have to be updated"
        where: mfb_params_base_points_bool_exp!
    ): mfb_params_base_points_mutation_response
    "update single row of the table: \"mfb_params.base_points\""
    update_mfb_params_base_points_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: mfb_params_base_points_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: mfb_params_base_points_set_input,
        pk_columns: mfb_params_base_points_pk_columns_input!
    ): mfb_params_base_points
    "update multiples rows of table: \"mfb_params.base_points\""
    update_mfb_params_base_points_many(
        "updates to execute, in order"
        updates: [mfb_params_base_points_updates!]!
    ): [mfb_params_base_points_mutation_response]
    "update data of the table: \"mfb_params.parts\""
    update_mfb_params_parts(
        "sets the columns of the filtered rows to the given values"
        _set: mfb_params_parts_set_input,
        "filter the rows which have to be updated"
        where: mfb_params_parts_bool_exp!
    ): mfb_params_parts_mutation_response
    "update single row of the table: \"mfb_params.parts\""
    update_mfb_params_parts_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: mfb_params_parts_set_input,
        pk_columns: mfb_params_parts_pk_columns_input!
    ): mfb_params_parts
    "update multiples rows of table: \"mfb_params.parts\""
    update_mfb_params_parts_many(
        "updates to execute, in order"
        updates: [mfb_params_parts_updates!]!
    ): [mfb_params_parts_mutation_response]
    "update data of the table: \"objects_hub\""
    update_objects_hub(
        "sets the columns of the filtered rows to the given values"
        _set: objects_hub_set_input,
        "filter the rows which have to be updated"
        where: objects_hub_bool_exp!
    ): objects_hub_mutation_response
    "update single row of the table: \"objects_hub\""
    update_objects_hub_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: objects_hub_set_input,
        pk_columns: objects_hub_pk_columns_input!
    ): objects_hub
    "update multiples rows of table: \"objects_hub\""
    update_objects_hub_many(
        "updates to execute, in order"
        updates: [objects_hub_updates!]!
    ): [objects_hub_mutation_response]
    "update data of the table: \"platform.hosts\""
    update_platform_hosts(
        "sets the columns of the filtered rows to the given values"
        _set: platform_hosts_set_input,
        "filter the rows which have to be updated"
        where: platform_hosts_bool_exp!
    ): platform_hosts_mutation_response
    "update single row of the table: \"platform.hosts\""
    update_platform_hosts_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: platform_hosts_set_input,
        pk_columns: platform_hosts_pk_columns_input!
    ): platform_hosts
    "update multiples rows of table: \"platform.hosts\""
    update_platform_hosts_many(
        "updates to execute, in order"
        updates: [platform_hosts_updates!]!
    ): [platform_hosts_mutation_response]
    "update data of the table: \"platform.service\""
    update_platform_service(
        "sets the columns of the filtered rows to the given values"
        _set: platform_service_set_input,
        "filter the rows which have to be updated"
        where: platform_service_bool_exp!
    ): platform_service_mutation_response
    "update data of the table: \"platform.service_attributes\""
    update_platform_service_attributes(
        "increments the numeric columns with given value of the filtered values"
        _inc: platform_service_attributes_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: platform_service_attributes_set_input,
        "filter the rows which have to be updated"
        where: platform_service_attributes_bool_exp!
    ): platform_service_attributes_mutation_response
    "update single row of the table: \"platform.service_attributes\""
    update_platform_service_attributes_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: platform_service_attributes_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: platform_service_attributes_set_input,
        pk_columns: platform_service_attributes_pk_columns_input!
    ): platform_service_attributes
    "update multiples rows of table: \"platform.service_attributes\""
    update_platform_service_attributes_many(
        "updates to execute, in order"
        updates: [platform_service_attributes_updates!]!
    ): [platform_service_attributes_mutation_response]
    "update single row of the table: \"platform.service\""
    update_platform_service_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: platform_service_set_input,
        pk_columns: platform_service_pk_columns_input!
    ): platform_service
    "update multiples rows of table: \"platform.service\""
    update_platform_service_many(
        "updates to execute, in order"
        updates: [platform_service_updates!]!
    ): [platform_service_mutation_response]
    "update data of the table: \"platform.services\""
    update_platform_services(
        "sets the columns of the filtered rows to the given values"
        _set: platform_services_set_input,
        "filter the rows which have to be updated"
        where: platform_services_bool_exp!
    ): platform_services_mutation_response
    "update multiples rows of table: \"platform.services\""
    update_platform_services_many(
        "updates to execute, in order"
        updates: [platform_services_updates!]!
    ): [platform_services_mutation_response]
    "update data of the table: \"platform.subscribes\""
    update_platform_subscribes(
        "increments the numeric columns with given value of the filtered values"
        _inc: platform_subscribes_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: platform_subscribes_set_input,
        "filter the rows which have to be updated"
        where: platform_subscribes_bool_exp!
    ): platform_subscribes_mutation_response
    "update single row of the table: \"platform.subscribes\""
    update_platform_subscribes_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: platform_subscribes_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: platform_subscribes_set_input,
        pk_columns: platform_subscribes_pk_columns_input!
    ): platform_subscribes
    "update multiples rows of table: \"platform.subscribes\""
    update_platform_subscribes_many(
        "updates to execute, in order"
        updates: [platform_subscribes_updates!]!
    ): [platform_subscribes_mutation_response]
    "update data of the table: \"platform.topics\""
    update_platform_topics(
        "sets the columns of the filtered rows to the given values"
        _set: platform_topics_set_input,
        "filter the rows which have to be updated"
        where: platform_topics_bool_exp!
    ): platform_topics_mutation_response
    "update single row of the table: \"platform.topics\""
    update_platform_topics_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: platform_topics_set_input,
        pk_columns: platform_topics_pk_columns_input!
    ): platform_topics
    "update multiples rows of table: \"platform.topics\""
    update_platform_topics_many(
        "updates to execute, in order"
        updates: [platform_topics_updates!]!
    ): [platform_topics_mutation_response]
    "update data of the table: \"survey.ceiling\""
    update_survey_ceiling(
        "increments the numeric columns with given value of the filtered values"
        _inc: survey_ceiling_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: survey_ceiling_set_input,
        "filter the rows which have to be updated"
        where: survey_ceiling_bool_exp!
    ): survey_ceiling_mutation_response
    "update single row of the table: \"survey.ceiling\""
    update_survey_ceiling_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: survey_ceiling_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: survey_ceiling_set_input,
        pk_columns: survey_ceiling_pk_columns_input!
    ): survey_ceiling
    "update multiples rows of table: \"survey.ceiling\""
    update_survey_ceiling_many(
        "updates to execute, in order"
        updates: [survey_ceiling_updates!]!
    ): [survey_ceiling_mutation_response]
    "update data of the table: \"threejs.types\""
    update_threejs_types(
        "sets the columns of the filtered rows to the given values"
        _set: threejs_types_set_input,
        "filter the rows which have to be updated"
        where: threejs_types_bool_exp!
    ): threejs_types_mutation_response
    "update single row of the table: \"threejs.types\""
    update_threejs_types_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: threejs_types_set_input,
        pk_columns: threejs_types_pk_columns_input!
    ): threejs_types
    "update multiples rows of table: \"threejs.types\""
    update_threejs_types_many(
        "updates to execute, in order"
        updates: [threejs_types_updates!]!
    ): [threejs_types_mutation_response]
}

"columns and relationships of \"objects_hub\""
type objects_hub {
    children: oidvector
    name: String
    type: String
    "An object relationship"
    type_relay: threejs_types
    uuid: uuid!
}

"aggregated selection of \"objects_hub\""
type objects_hub_aggregate {
    aggregate: objects_hub_aggregate_fields
    nodes: [objects_hub!]!
}

"aggregate fields of \"objects_hub\""
type objects_hub_aggregate_fields {
    count(columns: [objects_hub_select_column!], distinct: Boolean): Int!
    max: objects_hub_max_fields
    min: objects_hub_min_fields
}

"aggregate max on columns"
type objects_hub_max_fields {
    name: String
    type: String
    uuid: uuid
}

"aggregate min on columns"
type objects_hub_min_fields {
    name: String
    type: String
    uuid: uuid
}

"response of any mutation on the table \"objects_hub\""
type objects_hub_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [objects_hub!]!
}

"columns and relationships of \"platform.hosts\""
type platform_hosts {
    address: String!
    name: String!
    "An array relationship"
    services(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): [platform_services!]!
    "An aggregate relationship"
    services_aggregate(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): platform_services_aggregate!
}

"aggregated selection of \"platform.hosts\""
type platform_hosts_aggregate {
    aggregate: platform_hosts_aggregate_fields
    nodes: [platform_hosts!]!
}

"aggregate fields of \"platform.hosts\""
type platform_hosts_aggregate_fields {
    count(columns: [platform_hosts_select_column!], distinct: Boolean): Int!
    max: platform_hosts_max_fields
    min: platform_hosts_min_fields
}

"aggregate max on columns"
type platform_hosts_max_fields {
    address: String
    name: String
}

"aggregate min on columns"
type platform_hosts_min_fields {
    address: String
    name: String
}

"response of any mutation on the table \"platform.hosts\""
type platform_hosts_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [platform_hosts!]!
}

"columns and relationships of \"platform.service\""
type platform_service {
    "An object relationship"
    attributes: platform_service_attributes
    "An array relationship"
    hosts(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): [platform_services!]!
    "An aggregate relationship"
    hosts_aggregate(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): platform_services_aggregate!
    "An array relationship"
    subscribes(
        "distinct select on columns"
        distinct_on: [platform_subscribes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_subscribes_order_by!],
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): [platform_subscribes!]!
    "An aggregate relationship"
    subscribes_aggregate(
        "distinct select on columns"
        distinct_on: [platform_subscribes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_subscribes_order_by!],
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): platform_subscribes_aggregate!
    value: String!
}

"aggregated selection of \"platform.service\""
type platform_service_aggregate {
    aggregate: platform_service_aggregate_fields
    nodes: [platform_service!]!
}

"aggregate fields of \"platform.service\""
type platform_service_aggregate_fields {
    count(columns: [platform_service_select_column!], distinct: Boolean): Int!
    max: platform_service_max_fields
    min: platform_service_min_fields
}

"columns and relationships of \"platform.service_attributes\""
type platform_service_attributes {
    "An array relationship"
    endpoints(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): [platform_services!]!
    "An aggregate relationship"
    endpoints_aggregate(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): platform_services_aggregate!
    name: platform_service_enum!
    port: Int!
    "An object relationship"
    service: platform_service!
    url: String!
}

"aggregated selection of \"platform.service_attributes\""
type platform_service_attributes_aggregate {
    aggregate: platform_service_attributes_aggregate_fields
    nodes: [platform_service_attributes!]!
}

"aggregate fields of \"platform.service_attributes\""
type platform_service_attributes_aggregate_fields {
    avg: platform_service_attributes_avg_fields
    count(columns: [platform_service_attributes_select_column!], distinct: Boolean): Int!
    max: platform_service_attributes_max_fields
    min: platform_service_attributes_min_fields
    stddev: platform_service_attributes_stddev_fields
    stddev_pop: platform_service_attributes_stddev_pop_fields
    stddev_samp: platform_service_attributes_stddev_samp_fields
    sum: platform_service_attributes_sum_fields
    var_pop: platform_service_attributes_var_pop_fields
    var_samp: platform_service_attributes_var_samp_fields
    variance: platform_service_attributes_variance_fields
}

"aggregate avg on columns"
type platform_service_attributes_avg_fields {
    port: Float
}

"aggregate max on columns"
type platform_service_attributes_max_fields {
    port: Int
    url: String
}

"aggregate min on columns"
type platform_service_attributes_min_fields {
    port: Int
    url: String
}

"response of any mutation on the table \"platform.service_attributes\""
type platform_service_attributes_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [platform_service_attributes!]!
}

"aggregate stddev on columns"
type platform_service_attributes_stddev_fields {
    port: Float
}

"aggregate stddev_pop on columns"
type platform_service_attributes_stddev_pop_fields {
    port: Float
}

"aggregate stddev_samp on columns"
type platform_service_attributes_stddev_samp_fields {
    port: Float
}

"aggregate sum on columns"
type platform_service_attributes_sum_fields {
    port: Int
}

"aggregate var_pop on columns"
type platform_service_attributes_var_pop_fields {
    port: Float
}

"aggregate var_samp on columns"
type platform_service_attributes_var_samp_fields {
    port: Float
}

"aggregate variance on columns"
type platform_service_attributes_variance_fields {
    port: Float
}

"aggregate max on columns"
type platform_service_max_fields {
    value: String
}

"aggregate min on columns"
type platform_service_min_fields {
    value: String
}

"response of any mutation on the table \"platform.service\""
type platform_service_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [platform_service!]!
}

"columns and relationships of \"platform.services\""
type platform_services {
    created_at: timestamptz
    "An object relationship"
    host: platform_hosts!
    host_name: platform_hosts_enum!
    "An object relationship"
    service: platform_service
    service_name: platform_service_enum!
}

"aggregated selection of \"platform.services\""
type platform_services_aggregate {
    aggregate: platform_services_aggregate_fields
    nodes: [platform_services!]!
}

"aggregate fields of \"platform.services\""
type platform_services_aggregate_fields {
    count(columns: [platform_services_select_column!], distinct: Boolean): Int!
    max: platform_services_max_fields
    min: platform_services_min_fields
}

"aggregate max on columns"
type platform_services_max_fields {
    created_at: timestamptz
}

"aggregate min on columns"
type platform_services_min_fields {
    created_at: timestamptz
}

"response of any mutation on the table \"platform.services\""
type platform_services_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [platform_services!]!
}

"columns and relationships of \"platform.subscribes\""
type platform_subscribes {
    id: Int!
    service: platform_service_enum!
    "An object relationship"
    serviceByTopic: platform_service!
    topic: platform_topics_enum!
    "An object relationship"
    topicByService: platform_topics!
}

"aggregated selection of \"platform.subscribes\""
type platform_subscribes_aggregate {
    aggregate: platform_subscribes_aggregate_fields
    nodes: [platform_subscribes!]!
}

"aggregate fields of \"platform.subscribes\""
type platform_subscribes_aggregate_fields {
    avg: platform_subscribes_avg_fields
    count(columns: [platform_subscribes_select_column!], distinct: Boolean): Int!
    max: platform_subscribes_max_fields
    min: platform_subscribes_min_fields
    stddev: platform_subscribes_stddev_fields
    stddev_pop: platform_subscribes_stddev_pop_fields
    stddev_samp: platform_subscribes_stddev_samp_fields
    sum: platform_subscribes_sum_fields
    var_pop: platform_subscribes_var_pop_fields
    var_samp: platform_subscribes_var_samp_fields
    variance: platform_subscribes_variance_fields
}

"aggregate avg on columns"
type platform_subscribes_avg_fields {
    id: Float
}

"aggregate max on columns"
type platform_subscribes_max_fields {
    id: Int
}

"aggregate min on columns"
type platform_subscribes_min_fields {
    id: Int
}

"response of any mutation on the table \"platform.subscribes\""
type platform_subscribes_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [platform_subscribes!]!
}

"aggregate stddev on columns"
type platform_subscribes_stddev_fields {
    id: Float
}

"aggregate stddev_pop on columns"
type platform_subscribes_stddev_pop_fields {
    id: Float
}

"aggregate stddev_samp on columns"
type platform_subscribes_stddev_samp_fields {
    id: Float
}

"aggregate sum on columns"
type platform_subscribes_sum_fields {
    id: Int
}

"aggregate var_pop on columns"
type platform_subscribes_var_pop_fields {
    id: Float
}

"aggregate var_samp on columns"
type platform_subscribes_var_samp_fields {
    id: Float
}

"aggregate variance on columns"
type platform_subscribes_variance_fields {
    id: Float
}

"columns and relationships of \"platform.topics\""
type platform_topics {
    "An array relationship"
    services(
        "distinct select on columns"
        distinct_on: [platform_service_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_attributes_order_by!],
        "filter the rows returned"
        where: platform_service_attributes_bool_exp
    ): [platform_service_attributes!]!
    "An aggregate relationship"
    services_aggregate(
        "distinct select on columns"
        distinct_on: [platform_service_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_attributes_order_by!],
        "filter the rows returned"
        where: platform_service_attributes_bool_exp
    ): platform_service_attributes_aggregate!
    "An array relationship"
    subscribes(
        "distinct select on columns"
        distinct_on: [platform_subscribes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_subscribes_order_by!],
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): [platform_subscribes!]!
    "An aggregate relationship"
    subscribes_aggregate(
        "distinct select on columns"
        distinct_on: [platform_subscribes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_subscribes_order_by!],
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): platform_subscribes_aggregate!
    value: String!
}

"aggregated selection of \"platform.topics\""
type platform_topics_aggregate {
    aggregate: platform_topics_aggregate_fields
    nodes: [platform_topics!]!
}

"aggregate fields of \"platform.topics\""
type platform_topics_aggregate_fields {
    count(columns: [platform_topics_select_column!], distinct: Boolean): Int!
    max: platform_topics_max_fields
    min: platform_topics_min_fields
}

"aggregate max on columns"
type platform_topics_max_fields {
    value: String
}

"aggregate min on columns"
type platform_topics_min_fields {
    value: String
}

"response of any mutation on the table \"platform.topics\""
type platform_topics_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [platform_topics!]!
}

type query_root {
    "query _Entity union"
    _entities(representations: [_Any!]!): _Entity
    _service: _Service!
    "fetch data from the table: \"lht_triangles.connectors\""
    lht_triangles_connectors(
        "distinct select on columns"
        distinct_on: [lht_triangles_connectors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_connectors_order_by!],
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): [lht_triangles_connectors!]!
    "fetch aggregated fields from the table: \"lht_triangles.connectors\""
    lht_triangles_connectors_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_connectors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_connectors_order_by!],
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): lht_triangles_connectors_aggregate!
    "fetch data from the table: \"lht_triangles.connectors\" using primary key columns"
    lht_triangles_connectors_by_pk(name: String!): lht_triangles_connectors
    "fetch data from the table: \"lht_triangles.contours\""
    lht_triangles_contours(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "fetch aggregated fields from the table: \"lht_triangles.contours\""
    lht_triangles_contours_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): lht_triangles_contours_aggregate!
    "fetch data from the table: \"lht_triangles.contours\" using primary key columns"
    lht_triangles_contours_by_pk(uuid: uuid!): lht_triangles_contours
    "fetch data from the table: \"lht_triangles.floors\""
    lht_triangles_floors(
        "distinct select on columns"
        distinct_on: [lht_triangles_floors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_floors_order_by!],
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): [lht_triangles_floors!]!
    "fetch aggregated fields from the table: \"lht_triangles.floors\""
    lht_triangles_floors_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_floors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_floors_order_by!],
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): lht_triangles_floors_aggregate!
    "fetch data from the table: \"lht_triangles.floors\" using primary key columns"
    lht_triangles_floors_by_pk(value: String!): lht_triangles_floors
    "fetch data from the table: \"lht_triangles.transforms\""
    lht_triangles_transforms(
        "distinct select on columns"
        distinct_on: [lht_triangles_transforms_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_transforms_order_by!],
        "filter the rows returned"
        where: lht_triangles_transforms_bool_exp
    ): [lht_triangles_transforms!]!
    "fetch aggregated fields from the table: \"lht_triangles.transforms\""
    lht_triangles_transforms_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_transforms_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_transforms_order_by!],
        "filter the rows returned"
        where: lht_triangles_transforms_bool_exp
    ): lht_triangles_transforms_aggregate!
    "fetch data from the table: \"lht_triangles.transforms\" using primary key columns"
    lht_triangles_transforms_by_pk(name: String!): lht_triangles_transforms
    "fetch data from the table: \"mfb_params.base_points\""
    mfb_params_base_points(
        "distinct select on columns"
        distinct_on: [mfb_params_base_points_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_base_points_order_by!],
        "filter the rows returned"
        where: mfb_params_base_points_bool_exp
    ): [mfb_params_base_points!]!
    "fetch aggregated fields from the table: \"mfb_params.base_points\""
    mfb_params_base_points_aggregate(
        "distinct select on columns"
        distinct_on: [mfb_params_base_points_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_base_points_order_by!],
        "filter the rows returned"
        where: mfb_params_base_points_bool_exp
    ): mfb_params_base_points_aggregate!
    "fetch data from the table: \"mfb_params.base_points\" using primary key columns"
    mfb_params_base_points_by_pk(name: String!, part_name: mfb_params_parts_enum!): mfb_params_base_points
    "fetch data from the table: \"mfb_params.parts\""
    mfb_params_parts(
        "distinct select on columns"
        distinct_on: [mfb_params_parts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_parts_order_by!],
        "filter the rows returned"
        where: mfb_params_parts_bool_exp
    ): [mfb_params_parts!]!
    "fetch aggregated fields from the table: \"mfb_params.parts\""
    mfb_params_parts_aggregate(
        "distinct select on columns"
        distinct_on: [mfb_params_parts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_parts_order_by!],
        "filter the rows returned"
        where: mfb_params_parts_bool_exp
    ): mfb_params_parts_aggregate!
    "fetch data from the table: \"mfb_params.parts\" using primary key columns"
    mfb_params_parts_by_pk(name: String!): mfb_params_parts
    "fetch data from the table: \"objects_hub\""
    objects_hub(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): [objects_hub!]!
    "fetch aggregated fields from the table: \"objects_hub\""
    objects_hub_aggregate(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): objects_hub_aggregate!
    "fetch data from the table: \"objects_hub\" using primary key columns"
    objects_hub_by_pk(uuid: uuid!): objects_hub
    "fetch data from the table: \"platform.hosts\""
    platform_hosts(
        "distinct select on columns"
        distinct_on: [platform_hosts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_hosts_order_by!],
        "filter the rows returned"
        where: platform_hosts_bool_exp
    ): [platform_hosts!]!
    "fetch aggregated fields from the table: \"platform.hosts\""
    platform_hosts_aggregate(
        "distinct select on columns"
        distinct_on: [platform_hosts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_hosts_order_by!],
        "filter the rows returned"
        where: platform_hosts_bool_exp
    ): platform_hosts_aggregate!
    "fetch data from the table: \"platform.hosts\" using primary key columns"
    platform_hosts_by_pk(name: String!): platform_hosts
    "fetch data from the table: \"platform.service\""
    platform_service(
        "distinct select on columns"
        distinct_on: [platform_service_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_order_by!],
        "filter the rows returned"
        where: platform_service_bool_exp
    ): [platform_service!]!
    "fetch aggregated fields from the table: \"platform.service\""
    platform_service_aggregate(
        "distinct select on columns"
        distinct_on: [platform_service_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_order_by!],
        "filter the rows returned"
        where: platform_service_bool_exp
    ): platform_service_aggregate!
    "fetch data from the table: \"platform.service_attributes\""
    platform_service_attributes(
        "distinct select on columns"
        distinct_on: [platform_service_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_attributes_order_by!],
        "filter the rows returned"
        where: platform_service_attributes_bool_exp
    ): [platform_service_attributes!]!
    "fetch aggregated fields from the table: \"platform.service_attributes\""
    platform_service_attributes_aggregate(
        "distinct select on columns"
        distinct_on: [platform_service_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_attributes_order_by!],
        "filter the rows returned"
        where: platform_service_attributes_bool_exp
    ): platform_service_attributes_aggregate!
    "fetch data from the table: \"platform.service_attributes\" using primary key columns"
    platform_service_attributes_by_pk(port: Int!): platform_service_attributes
    "fetch data from the table: \"platform.service\" using primary key columns"
    platform_service_by_pk(value: String!): platform_service
    "fetch data from the table: \"platform.services\""
    platform_services(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): [platform_services!]!
    "fetch aggregated fields from the table: \"platform.services\""
    platform_services_aggregate(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): platform_services_aggregate!
    "fetch data from the table: \"platform.subscribes\""
    platform_subscribes(
        "distinct select on columns"
        distinct_on: [platform_subscribes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_subscribes_order_by!],
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): [platform_subscribes!]!
    "fetch aggregated fields from the table: \"platform.subscribes\""
    platform_subscribes_aggregate(
        "distinct select on columns"
        distinct_on: [platform_subscribes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_subscribes_order_by!],
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): platform_subscribes_aggregate!
    "fetch data from the table: \"platform.subscribes\" using primary key columns"
    platform_subscribes_by_pk(id: Int!): platform_subscribes
    "fetch data from the table: \"platform.topics\""
    platform_topics(
        "distinct select on columns"
        distinct_on: [platform_topics_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_topics_order_by!],
        "filter the rows returned"
        where: platform_topics_bool_exp
    ): [platform_topics!]!
    "fetch aggregated fields from the table: \"platform.topics\""
    platform_topics_aggregate(
        "distinct select on columns"
        distinct_on: [platform_topics_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_topics_order_by!],
        "filter the rows returned"
        where: platform_topics_bool_exp
    ): platform_topics_aggregate!
    "fetch data from the table: \"platform.topics\" using primary key columns"
    platform_topics_by_pk(value: String!): platform_topics
    "fetch data from the table: \"survey.ceiling\""
    survey_ceiling(
        "distinct select on columns"
        distinct_on: [survey_ceiling_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [survey_ceiling_order_by!],
        "filter the rows returned"
        where: survey_ceiling_bool_exp
    ): [survey_ceiling!]!
    "fetch aggregated fields from the table: \"survey.ceiling\""
    survey_ceiling_aggregate(
        "distinct select on columns"
        distinct_on: [survey_ceiling_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [survey_ceiling_order_by!],
        "filter the rows returned"
        where: survey_ceiling_bool_exp
    ): survey_ceiling_aggregate!
    "fetch data from the table: \"survey.ceiling\" using primary key columns"
    survey_ceiling_by_pk(id: Int!): survey_ceiling
    "fetch data from the table: \"threejs.types\""
    threejs_types(
        "distinct select on columns"
        distinct_on: [threejs_types_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [threejs_types_order_by!],
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): [threejs_types!]!
    "fetch aggregated fields from the table: \"threejs.types\""
    threejs_types_aggregate(
        "distinct select on columns"
        distinct_on: [threejs_types_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [threejs_types_order_by!],
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): threejs_types_aggregate!
    "fetch data from the table: \"threejs.types\" using primary key columns"
    threejs_types_by_pk(value: String!): threejs_types
}

type subscription_root {
    "fetch data from the table: \"lht_triangles.connectors\""
    lht_triangles_connectors(
        "distinct select on columns"
        distinct_on: [lht_triangles_connectors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_connectors_order_by!],
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): [lht_triangles_connectors!]!
    "fetch aggregated fields from the table: \"lht_triangles.connectors\""
    lht_triangles_connectors_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_connectors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_connectors_order_by!],
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): lht_triangles_connectors_aggregate!
    "fetch data from the table: \"lht_triangles.connectors\" using primary key columns"
    lht_triangles_connectors_by_pk(name: String!): lht_triangles_connectors
    "fetch data from the table in a streaming manner: \"lht_triangles.connectors\""
    lht_triangles_connectors_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_triangles_connectors_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): [lht_triangles_connectors!]!
    "fetch data from the table: \"lht_triangles.contours\""
    lht_triangles_contours(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "fetch aggregated fields from the table: \"lht_triangles.contours\""
    lht_triangles_contours_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): lht_triangles_contours_aggregate!
    "fetch data from the table: \"lht_triangles.contours\" using primary key columns"
    lht_triangles_contours_by_pk(uuid: uuid!): lht_triangles_contours
    "fetch data from the table in a streaming manner: \"lht_triangles.contours\""
    lht_triangles_contours_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_triangles_contours_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "fetch data from the table: \"lht_triangles.floors\""
    lht_triangles_floors(
        "distinct select on columns"
        distinct_on: [lht_triangles_floors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_floors_order_by!],
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): [lht_triangles_floors!]!
    "fetch aggregated fields from the table: \"lht_triangles.floors\""
    lht_triangles_floors_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_floors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_floors_order_by!],
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): lht_triangles_floors_aggregate!
    "fetch data from the table: \"lht_triangles.floors\" using primary key columns"
    lht_triangles_floors_by_pk(value: String!): lht_triangles_floors
    "fetch data from the table in a streaming manner: \"lht_triangles.floors\""
    lht_triangles_floors_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_triangles_floors_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): [lht_triangles_floors!]!
    "fetch data from the table: \"lht_triangles.transforms\""
    lht_triangles_transforms(
        "distinct select on columns"
        distinct_on: [lht_triangles_transforms_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_transforms_order_by!],
        "filter the rows returned"
        where: lht_triangles_transforms_bool_exp
    ): [lht_triangles_transforms!]!
    "fetch aggregated fields from the table: \"lht_triangles.transforms\""
    lht_triangles_transforms_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_transforms_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_transforms_order_by!],
        "filter the rows returned"
        where: lht_triangles_transforms_bool_exp
    ): lht_triangles_transforms_aggregate!
    "fetch data from the table: \"lht_triangles.transforms\" using primary key columns"
    lht_triangles_transforms_by_pk(name: String!): lht_triangles_transforms
    "fetch data from the table in a streaming manner: \"lht_triangles.transforms\""
    lht_triangles_transforms_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_triangles_transforms_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_triangles_transforms_bool_exp
    ): [lht_triangles_transforms!]!
    "fetch data from the table: \"mfb_params.base_points\""
    mfb_params_base_points(
        "distinct select on columns"
        distinct_on: [mfb_params_base_points_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_base_points_order_by!],
        "filter the rows returned"
        where: mfb_params_base_points_bool_exp
    ): [mfb_params_base_points!]!
    "fetch aggregated fields from the table: \"mfb_params.base_points\""
    mfb_params_base_points_aggregate(
        "distinct select on columns"
        distinct_on: [mfb_params_base_points_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_base_points_order_by!],
        "filter the rows returned"
        where: mfb_params_base_points_bool_exp
    ): mfb_params_base_points_aggregate!
    "fetch data from the table: \"mfb_params.base_points\" using primary key columns"
    mfb_params_base_points_by_pk(name: String!, part_name: mfb_params_parts_enum!): mfb_params_base_points
    "fetch data from the table in a streaming manner: \"mfb_params.base_points\""
    mfb_params_base_points_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [mfb_params_base_points_stream_cursor_input]!,
        "filter the rows returned"
        where: mfb_params_base_points_bool_exp
    ): [mfb_params_base_points!]!
    "fetch data from the table: \"mfb_params.parts\""
    mfb_params_parts(
        "distinct select on columns"
        distinct_on: [mfb_params_parts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_parts_order_by!],
        "filter the rows returned"
        where: mfb_params_parts_bool_exp
    ): [mfb_params_parts!]!
    "fetch aggregated fields from the table: \"mfb_params.parts\""
    mfb_params_parts_aggregate(
        "distinct select on columns"
        distinct_on: [mfb_params_parts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [mfb_params_parts_order_by!],
        "filter the rows returned"
        where: mfb_params_parts_bool_exp
    ): mfb_params_parts_aggregate!
    "fetch data from the table: \"mfb_params.parts\" using primary key columns"
    mfb_params_parts_by_pk(name: String!): mfb_params_parts
    "fetch data from the table in a streaming manner: \"mfb_params.parts\""
    mfb_params_parts_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [mfb_params_parts_stream_cursor_input]!,
        "filter the rows returned"
        where: mfb_params_parts_bool_exp
    ): [mfb_params_parts!]!
    "fetch data from the table: \"objects_hub\""
    objects_hub(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): [objects_hub!]!
    "fetch aggregated fields from the table: \"objects_hub\""
    objects_hub_aggregate(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): objects_hub_aggregate!
    "fetch data from the table: \"objects_hub\" using primary key columns"
    objects_hub_by_pk(uuid: uuid!): objects_hub
    "fetch data from the table in a streaming manner: \"objects_hub\""
    objects_hub_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [objects_hub_stream_cursor_input]!,
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): [objects_hub!]!
    "fetch data from the table: \"platform.hosts\""
    platform_hosts(
        "distinct select on columns"
        distinct_on: [platform_hosts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_hosts_order_by!],
        "filter the rows returned"
        where: platform_hosts_bool_exp
    ): [platform_hosts!]!
    "fetch aggregated fields from the table: \"platform.hosts\""
    platform_hosts_aggregate(
        "distinct select on columns"
        distinct_on: [platform_hosts_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_hosts_order_by!],
        "filter the rows returned"
        where: platform_hosts_bool_exp
    ): platform_hosts_aggregate!
    "fetch data from the table: \"platform.hosts\" using primary key columns"
    platform_hosts_by_pk(name: String!): platform_hosts
    "fetch data from the table in a streaming manner: \"platform.hosts\""
    platform_hosts_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [platform_hosts_stream_cursor_input]!,
        "filter the rows returned"
        where: platform_hosts_bool_exp
    ): [platform_hosts!]!
    "fetch data from the table: \"platform.service\""
    platform_service(
        "distinct select on columns"
        distinct_on: [platform_service_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_order_by!],
        "filter the rows returned"
        where: platform_service_bool_exp
    ): [platform_service!]!
    "fetch aggregated fields from the table: \"platform.service\""
    platform_service_aggregate(
        "distinct select on columns"
        distinct_on: [platform_service_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_order_by!],
        "filter the rows returned"
        where: platform_service_bool_exp
    ): platform_service_aggregate!
    "fetch data from the table: \"platform.service_attributes\""
    platform_service_attributes(
        "distinct select on columns"
        distinct_on: [platform_service_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_attributes_order_by!],
        "filter the rows returned"
        where: platform_service_attributes_bool_exp
    ): [platform_service_attributes!]!
    "fetch aggregated fields from the table: \"platform.service_attributes\""
    platform_service_attributes_aggregate(
        "distinct select on columns"
        distinct_on: [platform_service_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_service_attributes_order_by!],
        "filter the rows returned"
        where: platform_service_attributes_bool_exp
    ): platform_service_attributes_aggregate!
    "fetch data from the table: \"platform.service_attributes\" using primary key columns"
    platform_service_attributes_by_pk(port: Int!): platform_service_attributes
    "fetch data from the table in a streaming manner: \"platform.service_attributes\""
    platform_service_attributes_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [platform_service_attributes_stream_cursor_input]!,
        "filter the rows returned"
        where: platform_service_attributes_bool_exp
    ): [platform_service_attributes!]!
    "fetch data from the table: \"platform.service\" using primary key columns"
    platform_service_by_pk(value: String!): platform_service
    "fetch data from the table in a streaming manner: \"platform.service\""
    platform_service_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [platform_service_stream_cursor_input]!,
        "filter the rows returned"
        where: platform_service_bool_exp
    ): [platform_service!]!
    "fetch data from the table: \"platform.services\""
    platform_services(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): [platform_services!]!
    "fetch aggregated fields from the table: \"platform.services\""
    platform_services_aggregate(
        "distinct select on columns"
        distinct_on: [platform_services_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_services_order_by!],
        "filter the rows returned"
        where: platform_services_bool_exp
    ): platform_services_aggregate!
    "fetch data from the table in a streaming manner: \"platform.services\""
    platform_services_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [platform_services_stream_cursor_input]!,
        "filter the rows returned"
        where: platform_services_bool_exp
    ): [platform_services!]!
    "fetch data from the table: \"platform.subscribes\""
    platform_subscribes(
        "distinct select on columns"
        distinct_on: [platform_subscribes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_subscribes_order_by!],
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): [platform_subscribes!]!
    "fetch aggregated fields from the table: \"platform.subscribes\""
    platform_subscribes_aggregate(
        "distinct select on columns"
        distinct_on: [platform_subscribes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_subscribes_order_by!],
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): platform_subscribes_aggregate!
    "fetch data from the table: \"platform.subscribes\" using primary key columns"
    platform_subscribes_by_pk(id: Int!): platform_subscribes
    "fetch data from the table in a streaming manner: \"platform.subscribes\""
    platform_subscribes_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [platform_subscribes_stream_cursor_input]!,
        "filter the rows returned"
        where: platform_subscribes_bool_exp
    ): [platform_subscribes!]!
    "fetch data from the table: \"platform.topics\""
    platform_topics(
        "distinct select on columns"
        distinct_on: [platform_topics_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_topics_order_by!],
        "filter the rows returned"
        where: platform_topics_bool_exp
    ): [platform_topics!]!
    "fetch aggregated fields from the table: \"platform.topics\""
    platform_topics_aggregate(
        "distinct select on columns"
        distinct_on: [platform_topics_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [platform_topics_order_by!],
        "filter the rows returned"
        where: platform_topics_bool_exp
    ): platform_topics_aggregate!
    "fetch data from the table: \"platform.topics\" using primary key columns"
    platform_topics_by_pk(value: String!): platform_topics
    "fetch data from the table in a streaming manner: \"platform.topics\""
    platform_topics_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [platform_topics_stream_cursor_input]!,
        "filter the rows returned"
        where: platform_topics_bool_exp
    ): [platform_topics!]!
    "fetch data from the table: \"survey.ceiling\""
    survey_ceiling(
        "distinct select on columns"
        distinct_on: [survey_ceiling_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [survey_ceiling_order_by!],
        "filter the rows returned"
        where: survey_ceiling_bool_exp
    ): [survey_ceiling!]!
    "fetch aggregated fields from the table: \"survey.ceiling\""
    survey_ceiling_aggregate(
        "distinct select on columns"
        distinct_on: [survey_ceiling_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [survey_ceiling_order_by!],
        "filter the rows returned"
        where: survey_ceiling_bool_exp
    ): survey_ceiling_aggregate!
    "fetch data from the table: \"survey.ceiling\" using primary key columns"
    survey_ceiling_by_pk(id: Int!): survey_ceiling
    "fetch data from the table in a streaming manner: \"survey.ceiling\""
    survey_ceiling_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [survey_ceiling_stream_cursor_input]!,
        "filter the rows returned"
        where: survey_ceiling_bool_exp
    ): [survey_ceiling!]!
    "fetch data from the table: \"threejs.types\""
    threejs_types(
        "distinct select on columns"
        distinct_on: [threejs_types_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [threejs_types_order_by!],
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): [threejs_types!]!
    "fetch aggregated fields from the table: \"threejs.types\""
    threejs_types_aggregate(
        "distinct select on columns"
        distinct_on: [threejs_types_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [threejs_types_order_by!],
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): threejs_types_aggregate!
    "fetch data from the table: \"threejs.types\" using primary key columns"
    threejs_types_by_pk(value: String!): threejs_types
    "fetch data from the table in a streaming manner: \"threejs.types\""
    threejs_types_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [threejs_types_stream_cursor_input]!,
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): [threejs_types!]!
}

"triangle ceiling survey"
type survey_ceiling {
    "An object relationship"
    floor: lht_triangles_floors
    floor_name: String!
    id: Int!
    "geodesist index"
    index: Int
    tag: String
    "An object relationship"
    transform: lht_triangles_transforms
    transform_name: String!
    update_at: timestamp!
    x: float8
    y: float8
    z: float8
}

"aggregated selection of \"survey.ceiling\""
type survey_ceiling_aggregate {
    aggregate: survey_ceiling_aggregate_fields
    nodes: [survey_ceiling!]!
}

"aggregate fields of \"survey.ceiling\""
type survey_ceiling_aggregate_fields {
    avg: survey_ceiling_avg_fields
    count(columns: [survey_ceiling_select_column!], distinct: Boolean): Int!
    max: survey_ceiling_max_fields
    min: survey_ceiling_min_fields
    stddev: survey_ceiling_stddev_fields
    stddev_pop: survey_ceiling_stddev_pop_fields
    stddev_samp: survey_ceiling_stddev_samp_fields
    sum: survey_ceiling_sum_fields
    var_pop: survey_ceiling_var_pop_fields
    var_samp: survey_ceiling_var_samp_fields
    variance: survey_ceiling_variance_fields
}

"aggregate avg on columns"
type survey_ceiling_avg_fields {
    id: Float
    "geodesist index"
    index: Float
    x: Float
    y: Float
    z: Float
}

"aggregate max on columns"
type survey_ceiling_max_fields {
    floor_name: String
    id: Int
    "geodesist index"
    index: Int
    tag: String
    transform_name: String
    update_at: timestamp
    x: float8
    y: float8
    z: float8
}

"aggregate min on columns"
type survey_ceiling_min_fields {
    floor_name: String
    id: Int
    "geodesist index"
    index: Int
    tag: String
    transform_name: String
    update_at: timestamp
    x: float8
    y: float8
    z: float8
}

"response of any mutation on the table \"survey.ceiling\""
type survey_ceiling_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [survey_ceiling!]!
}

"aggregate stddev on columns"
type survey_ceiling_stddev_fields {
    id: Float
    "geodesist index"
    index: Float
    x: Float
    y: Float
    z: Float
}

"aggregate stddev_pop on columns"
type survey_ceiling_stddev_pop_fields {
    id: Float
    "geodesist index"
    index: Float
    x: Float
    y: Float
    z: Float
}

"aggregate stddev_samp on columns"
type survey_ceiling_stddev_samp_fields {
    id: Float
    "geodesist index"
    index: Float
    x: Float
    y: Float
    z: Float
}

"aggregate sum on columns"
type survey_ceiling_sum_fields {
    id: Int
    "geodesist index"
    index: Int
    x: float8
    y: float8
    z: float8
}

"aggregate var_pop on columns"
type survey_ceiling_var_pop_fields {
    id: Float
    "geodesist index"
    index: Float
    x: Float
    y: Float
    z: Float
}

"aggregate var_samp on columns"
type survey_ceiling_var_samp_fields {
    id: Float
    "geodesist index"
    index: Float
    x: Float
    y: Float
    z: Float
}

"aggregate variance on columns"
type survey_ceiling_variance_fields {
    id: Float
    "geodesist index"
    index: Float
    x: Float
    y: Float
    z: Float
}

"columns and relationships of \"threejs.types\""
type threejs_types {
    comment: String
    "An array relationship"
    objects(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): [objects_hub!]!
    "An aggregate relationship"
    objects_aggregate(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): objects_hub_aggregate!
    value: String!
}

"aggregated selection of \"threejs.types\""
type threejs_types_aggregate {
    aggregate: threejs_types_aggregate_fields
    nodes: [threejs_types!]!
}

"aggregate fields of \"threejs.types\""
type threejs_types_aggregate_fields {
    count(columns: [threejs_types_select_column!], distinct: Boolean): Int!
    max: threejs_types_max_fields
    min: threejs_types_min_fields
}

"aggregate max on columns"
type threejs_types_max_fields {
    comment: String
    value: String
}

"aggregate min on columns"
type threejs_types_min_fields {
    comment: String
    value: String
}

"response of any mutation on the table \"threejs.types\""
type threejs_types_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [threejs_types!]!
}

"ordering argument of a cursor"
enum cursor_ordering {
    "ascending ordering of the cursor"
    ASC
    "descending ordering of the cursor"
    DESC
}

"unique or primary key constraints on table \"lht_triangles.connectors\""
enum lht_triangles_connectors_constraint {
    "unique or primary key constraint on columns \"name\""
    connectors_name_key
    "unique or primary key constraint on columns \"name\""
    connectors_pkey
}

"select columns of table \"lht_triangles.connectors\""
enum lht_triangles_connectors_select_column {
    "column name"
    from
    "column name"
    name
    "column name"
    offset
    "column name"
    production
    "column name"
    type
}

"update columns of table \"lht_triangles.connectors\""
enum lht_triangles_connectors_update_column {
    "column name"
    from
    "column name"
    name
    "column name"
    offset
    "column name"
    production
    "column name"
    type
}

"unique or primary key constraints on table \"lht_triangles.contours\""
enum lht_triangles_contours_constraint {
    "unique or primary key constraint on columns \"uuid\""
    all_pkey
}

"select columns of table \"lht_triangles.contours\""
enum lht_triangles_contours_select_column {
    "column name"
    curve
    "column name"
    detail
    "column name"
    floor
    "column name"
    uuid
}

"update columns of table \"lht_triangles.contours\""
enum lht_triangles_contours_update_column {
    "column name"
    curve
    "column name"
    detail
    "column name"
    floor
    "column name"
    uuid
}

"unique or primary key constraints on table \"lht_triangles.floors\""
enum lht_triangles_floors_constraint {
    "unique or primary key constraint on columns \"value\""
    floors_pkey
}

enum lht_triangles_floors_enum {
    B1
    L1
    L2
    L2W
}

"select columns of table \"lht_triangles.floors\""
enum lht_triangles_floors_select_column {
    "column name"
    comment
    "column name"
    value
}

"update columns of table \"lht_triangles.floors\""
enum lht_triangles_floors_update_column {
    "column name"
    comment
    "column name"
    value
}

"unique or primary key constraints on table \"lht_triangles.transforms\""
enum lht_triangles_transforms_constraint {
    "unique or primary key constraint on columns \"name\""
    transforms_pkey
}

"select columns of table \"lht_triangles.transforms\""
enum lht_triangles_transforms_select_column {
    "column name"
    name
    "column name"
    value
}

"update columns of table \"lht_triangles.transforms\""
enum lht_triangles_transforms_update_column {
    "column name"
    name
    "column name"
    value
}

"unique or primary key constraints on table \"mfb_params.base_points\""
enum mfb_params_base_points_constraint {
    "unique or primary key constraint on columns \"name\", \"part_name\""
    base_points_pk
}

"select columns of table \"mfb_params.base_points\""
enum mfb_params_base_points_select_column {
    "column name"
    id
    "column name"
    name
    "column name"
    part_name
    "column name"
    update_at
    "column name"
    x
    "column name"
    y
    "column name"
    z
}

"update columns of table \"mfb_params.base_points\""
enum mfb_params_base_points_update_column {
    "column name"
    id
    "column name"
    name
    "column name"
    part_name
    "column name"
    update_at
    "column name"
    x
    "column name"
    y
    "column name"
    z
}

"unique or primary key constraints on table \"mfb_params.parts\""
enum mfb_params_parts_constraint {
    "unique or primary key constraint on columns \"name\""
    parts_pk
}

enum mfb_params_parts_enum {
    NE
    SW
}

"select columns of table \"mfb_params.parts\""
enum mfb_params_parts_select_column {
    "column name"
    comment
    "column name"
    name
}

"update columns of table \"mfb_params.parts\""
enum mfb_params_parts_update_column {
    "column name"
    comment
    "column name"
    name
}

"unique or primary key constraints on table \"objects_hub\""
enum objects_hub_constraint {
    "unique or primary key constraint on columns \"uuid\""
    objects_hub_pkey
}

"select columns of table \"objects_hub\""
enum objects_hub_select_column {
    "column name"
    children
    "column name"
    name
    "column name"
    type
    "column name"
    uuid
}

"update columns of table \"objects_hub\""
enum objects_hub_update_column {
    "column name"
    children
    "column name"
    name
    "column name"
    type
    "column name"
    uuid
}

"column ordering options"
enum order_by {
    "in ascending order, nulls last"
    asc
    "in ascending order, nulls first"
    asc_nulls_first
    "in ascending order, nulls last"
    asc_nulls_last
    "in descending order, nulls first"
    desc
    "in descending order, nulls first"
    desc_nulls_first
    "in descending order, nulls last"
    desc_nulls_last
}

"unique or primary key constraints on table \"platform.hosts\""
enum platform_hosts_constraint {
    "unique or primary key constraint on columns \"name\""
    hosts_pkey
}

enum platform_hosts_enum {
    "84.201.178.237"
    cluster
    "92.53.64.197"
    curie
    "127.0.0.1"
    localhost
    "84.201.140.137"
    storm
}

"select columns of table \"platform.hosts\""
enum platform_hosts_select_column {
    "column name"
    address
    "column name"
    name
}

"update columns of table \"platform.hosts\""
enum platform_hosts_update_column {
    "column name"
    address
    "column name"
    name
}

"unique or primary key constraints on table \"platform.service_attributes\""
enum platform_service_attributes_constraint {
    "unique or primary key constraint on columns \"port\""
    svc_attributes_pkey
    "unique or primary key constraint on columns \"name\""
    svc_attributes_svc_name_key
}

"select columns of table \"platform.service_attributes\""
enum platform_service_attributes_select_column {
    "column name"
    name
    "column name"
    port
    "column name"
    url
}

"update columns of table \"platform.service_attributes\""
enum platform_service_attributes_update_column {
    "column name"
    name
    "column name"
    port
    "column name"
    url
}

"unique or primary key constraints on table \"platform.service\""
enum platform_service_constraint {
    "unique or primary key constraint on columns \"value\""
    svc_name_key
    "unique or primary key constraint on columns \"value\""
    svc_pkey
}

enum platform_service_enum {
    blender
    freecad
    houdini
    nodjs
    pyodide
    pystuff
    python
    revit
    rhpyc
    rpyc
    tekla
    viewer
}

"select columns of table \"platform.service\""
enum platform_service_select_column {
    "column name"
    value
}

"update columns of table \"platform.service\""
enum platform_service_update_column {
    "column name"
    value
}

"select columns of table \"platform.services\""
enum platform_services_select_column {
    "column name"
    created_at
    "column name"
    host_name
    "column name"
    service_name
}

"unique or primary key constraints on table \"platform.subscribes\""
enum platform_subscribes_constraint {
    "unique or primary key constraint on columns \"id\""
    subscribes_id_key
    "unique or primary key constraint on columns \"id\""
    subscribes_pkey
}

"select columns of table \"platform.subscribes\""
enum platform_subscribes_select_column {
    "column name"
    id
    "column name"
    service
    "column name"
    topic
}

"update columns of table \"platform.subscribes\""
enum platform_subscribes_update_column {
    "column name"
    id
    "column name"
    service
    "column name"
    topic
}

"unique or primary key constraints on table \"platform.topics\""
enum platform_topics_constraint {
    "unique or primary key constraint on columns \"value\""
    topics_pkey
}

enum platform_topics_enum {
    FreeCAD
    Freecad
    Grasshopper
    Rhino
    RhinoGeometry
    fastapi
    mmcore
    pythonocc
    rhino3dm
}

"select columns of table \"platform.topics\""
enum platform_topics_select_column {
    "column name"
    value
}

"update columns of table \"platform.topics\""
enum platform_topics_update_column {
    "column name"
    value
}

"unique or primary key constraints on table \"survey.ceiling\""
enum survey_ceiling_constraint {
    "unique or primary key constraint on columns \"id\""
    ceiling_pk
}

"select columns of table \"survey.ceiling\""
enum survey_ceiling_select_column {
    "column name"
    floor_name
    "column name"
    id
    "column name"
    index
    "column name"
    tag
    "column name"
    transform_name
    "column name"
    update_at
    "column name"
    x
    "column name"
    y
    "column name"
    z
}

"update columns of table \"survey.ceiling\""
enum survey_ceiling_update_column {
    "column name"
    floor_name
    "column name"
    index
    "column name"
    tag
    "column name"
    transform_name
    "column name"
    update_at
    "column name"
    x
    "column name"
    y
    "column name"
    z
}

"unique or primary key constraints on table \"threejs.types\""
enum threejs_types_constraint {
    "unique or primary key constraint on columns \"value\""
    types_pkey
}

"select columns of table \"threejs.types\""
enum threejs_types_select_column {
    "column name"
    comment
    "column name"
    value
}

"update columns of table \"threejs.types\""
enum threejs_types_update_column {
    "column name"
    comment
    "column name"
    value
}

"Scalar _Any"
scalar _Any

scalar float8

scalar jsonb

scalar name

scalar numeric

scalar oidvector

scalar timestamp

scalar timestamptz

scalar uuid

"Boolean expression to compare columns of type \"Int\". All fields are combined with logical 'AND'."
input Int_comparison_exp {
    _eq: Int
    _gt: Int
    _gte: Int
    _in: [Int!]
    _is_null: Boolean
    _lt: Int
    _lte: Int
    _neq: Int
    _nin: [Int!]
}

"Boolean expression to compare columns of type \"String\". All fields are combined with logical 'AND'."
input String_comparison_exp {
    _eq: String
    _gt: String
    _gte: String
    "does the column match the given case-insensitive pattern"
    _ilike: String
    _in: [String!]
    "does the column match the given POSIX regular expression, case insensitive"
    _iregex: String
    _is_null: Boolean
    "does the column match the given pattern"
    _like: String
    _lt: String
    _lte: String
    _neq: String
    "does the column NOT match the given case-insensitive pattern"
    _nilike: String
    _nin: [String!]
    "does the column NOT match the given POSIX regular expression, case insensitive"
    _niregex: String
    "does the column NOT match the given pattern"
    _nlike: String
    "does the column NOT match the given POSIX regular expression, case sensitive"
    _nregex: String
    "does the column NOT match the given SQL regular expression"
    _nsimilar: String
    "does the column match the given POSIX regular expression, case sensitive"
    _regex: String
    "does the column match the given SQL regular expression"
    _similar: String
}

"Boolean expression to compare columns of type \"float8\". All fields are combined with logical 'AND'."
input float8_comparison_exp {
    _eq: float8
    _gt: float8
    _gte: float8
    _in: [float8!]
    _is_null: Boolean
    _lt: float8
    _lte: float8
    _neq: float8
    _nin: [float8!]
}

input jsonb_cast_exp {
    String: String_comparison_exp
}

"Boolean expression to compare columns of type \"jsonb\". All fields are combined with logical 'AND'."
input jsonb_comparison_exp {
    _cast: jsonb_cast_exp
    "is the column contained in the given json value"
    _contained_in: jsonb
    "does the column contain the given json value at the top level"
    _contains: jsonb
    _eq: jsonb
    _gt: jsonb
    _gte: jsonb
    "does the string exist as a top-level key in the column"
    _has_key: String
    "do all of these strings exist as top-level keys in the column"
    _has_keys_all: [String!]
    "do any of these strings exist as top-level keys in the column"
    _has_keys_any: [String!]
    _in: [jsonb!]
    _is_null: Boolean
    _lt: jsonb
    _lte: jsonb
    _neq: jsonb
    _nin: [jsonb!]
}

"Boolean expression to filter rows from the table \"lht_triangles.connectors\". All fields are combined with a logical 'AND'."
input lht_triangles_connectors_bool_exp {
    _and: [lht_triangles_connectors_bool_exp!]
    _not: lht_triangles_connectors_bool_exp
    _or: [lht_triangles_connectors_bool_exp!]
    contours: lht_triangles_contours_bool_exp
    contours_aggregate: lht_triangles_contours_aggregate_bool_exp
    from: String_comparison_exp
    name: String_comparison_exp
    offset: numeric_comparison_exp
    production: String_comparison_exp
    type: String_comparison_exp
}

"input type for incrementing numeric columns in table \"lht_triangles.connectors\""
input lht_triangles_connectors_inc_input {
    offset: numeric
}

"input type for inserting data into table \"lht_triangles.connectors\""
input lht_triangles_connectors_insert_input {
    contours: lht_triangles_contours_arr_rel_insert_input
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

"input type for inserting object relation for remote table \"lht_triangles.connectors\""
input lht_triangles_connectors_obj_rel_insert_input {
    data: lht_triangles_connectors_insert_input!
    "upsert condition"
    on_conflict: lht_triangles_connectors_on_conflict
}

"on_conflict condition type for table \"lht_triangles.connectors\""
input lht_triangles_connectors_on_conflict {
    constraint: lht_triangles_connectors_constraint!
    update_columns: [lht_triangles_connectors_update_column!]! = []
    where: lht_triangles_connectors_bool_exp
}

"Ordering options when selecting data from \"lht_triangles.connectors\"."
input lht_triangles_connectors_order_by {
    contours_aggregate: lht_triangles_contours_aggregate_order_by
    from: order_by
    name: order_by
    offset: order_by
    production: order_by
    type: order_by
}

"primary key columns input for table: lht_triangles.connectors"
input lht_triangles_connectors_pk_columns_input {
    name: String!
}

"input type for updating data in table \"lht_triangles.connectors\""
input lht_triangles_connectors_set_input {
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

"Streaming cursor of the table \"lht_triangles_connectors\""
input lht_triangles_connectors_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_triangles_connectors_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_triangles_connectors_stream_cursor_value_input {
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

input lht_triangles_connectors_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: lht_triangles_connectors_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: lht_triangles_connectors_set_input
    "filter the rows which have to be updated"
    where: lht_triangles_connectors_bool_exp!
}

input lht_triangles_contours_aggregate_bool_exp {
    count: lht_triangles_contours_aggregate_bool_exp_count
}

input lht_triangles_contours_aggregate_bool_exp_count {
    arguments: [lht_triangles_contours_select_column!]
    distinct: Boolean
    filter: lht_triangles_contours_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"lht_triangles.contours\""
input lht_triangles_contours_aggregate_order_by {
    count: order_by
    max: lht_triangles_contours_max_order_by
    min: lht_triangles_contours_min_order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input lht_triangles_contours_append_input {
    curve: jsonb
}

"input type for inserting array relation for remote table \"lht_triangles.contours\""
input lht_triangles_contours_arr_rel_insert_input {
    data: [lht_triangles_contours_insert_input!]!
    "upsert condition"
    on_conflict: lht_triangles_contours_on_conflict
}

"Boolean expression to filter rows from the table \"lht_triangles.contours\". All fields are combined with a logical 'AND'."
input lht_triangles_contours_bool_exp {
    _and: [lht_triangles_contours_bool_exp!]
    _not: lht_triangles_contours_bool_exp
    _or: [lht_triangles_contours_bool_exp!]
    connector: lht_triangles_connectors_bool_exp
    curve: jsonb_comparison_exp
    detail: name_comparison_exp
    floor: lht_triangles_floors_enum_comparison_exp
    floorByFloor: lht_triangles_floors_bool_exp
    uuid: uuid_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input lht_triangles_contours_delete_at_path_input {
    curve: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input lht_triangles_contours_delete_elem_input {
    curve: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input lht_triangles_contours_delete_key_input {
    curve: String
}

"input type for inserting data into table \"lht_triangles.contours\""
input lht_triangles_contours_insert_input {
    connector: lht_triangles_connectors_obj_rel_insert_input
    curve: jsonb
    detail: name
    floor: lht_triangles_floors_enum
    floorByFloor: lht_triangles_floors_obj_rel_insert_input
    uuid: uuid
}

"order by max() on columns of table \"lht_triangles.contours\""
input lht_triangles_contours_max_order_by {
    uuid: order_by
}

"order by min() on columns of table \"lht_triangles.contours\""
input lht_triangles_contours_min_order_by {
    uuid: order_by
}

"on_conflict condition type for table \"lht_triangles.contours\""
input lht_triangles_contours_on_conflict {
    constraint: lht_triangles_contours_constraint!
    update_columns: [lht_triangles_contours_update_column!]! = []
    where: lht_triangles_contours_bool_exp
}

"Ordering options when selecting data from \"lht_triangles.contours\"."
input lht_triangles_contours_order_by {
    connector: lht_triangles_connectors_order_by
    curve: order_by
    detail: order_by
    floor: order_by
    floorByFloor: lht_triangles_floors_order_by
    uuid: order_by
}

"primary key columns input for table: lht_triangles.contours"
input lht_triangles_contours_pk_columns_input {
    uuid: uuid!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input lht_triangles_contours_prepend_input {
    curve: jsonb
}

"input type for updating data in table \"lht_triangles.contours\""
input lht_triangles_contours_set_input {
    curve: jsonb
    detail: name
    floor: lht_triangles_floors_enum
    uuid: uuid
}

"Streaming cursor of the table \"lht_triangles_contours\""
input lht_triangles_contours_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_triangles_contours_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_triangles_contours_stream_cursor_value_input {
    curve: jsonb
    detail: name
    floor: lht_triangles_floors_enum
    uuid: uuid
}

input lht_triangles_contours_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: lht_triangles_contours_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: lht_triangles_contours_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: lht_triangles_contours_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: lht_triangles_contours_delete_key_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: lht_triangles_contours_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: lht_triangles_contours_set_input
    "filter the rows which have to be updated"
    where: lht_triangles_contours_bool_exp!
}

"Boolean expression to filter rows from the table \"lht_triangles.floors\". All fields are combined with a logical 'AND'."
input lht_triangles_floors_bool_exp {
    _and: [lht_triangles_floors_bool_exp!]
    _not: lht_triangles_floors_bool_exp
    _or: [lht_triangles_floors_bool_exp!]
    comment: String_comparison_exp
    entities: lht_triangles_contours_bool_exp
    entities_aggregate: lht_triangles_contours_aggregate_bool_exp
    value: String_comparison_exp
}

"Boolean expression to compare columns of type \"lht_triangles_floors_enum\". All fields are combined with logical 'AND'."
input lht_triangles_floors_enum_comparison_exp {
    _eq: lht_triangles_floors_enum
    _in: [lht_triangles_floors_enum!]
    _is_null: Boolean
    _neq: lht_triangles_floors_enum
    _nin: [lht_triangles_floors_enum!]
}

"input type for inserting data into table \"lht_triangles.floors\""
input lht_triangles_floors_insert_input {
    comment: String
    entities: lht_triangles_contours_arr_rel_insert_input
    value: String
}

"input type for inserting object relation for remote table \"lht_triangles.floors\""
input lht_triangles_floors_obj_rel_insert_input {
    data: lht_triangles_floors_insert_input!
    "upsert condition"
    on_conflict: lht_triangles_floors_on_conflict
}

"on_conflict condition type for table \"lht_triangles.floors\""
input lht_triangles_floors_on_conflict {
    constraint: lht_triangles_floors_constraint!
    update_columns: [lht_triangles_floors_update_column!]! = []
    where: lht_triangles_floors_bool_exp
}

"Ordering options when selecting data from \"lht_triangles.floors\"."
input lht_triangles_floors_order_by {
    comment: order_by
    entities_aggregate: lht_triangles_contours_aggregate_order_by
    value: order_by
}

"primary key columns input for table: lht_triangles.floors"
input lht_triangles_floors_pk_columns_input {
    value: String!
}

"input type for updating data in table \"lht_triangles.floors\""
input lht_triangles_floors_set_input {
    comment: String
    value: String
}

"Streaming cursor of the table \"lht_triangles_floors\""
input lht_triangles_floors_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_triangles_floors_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_triangles_floors_stream_cursor_value_input {
    comment: String
    value: String
}

input lht_triangles_floors_updates {
    "sets the columns of the filtered rows to the given values"
    _set: lht_triangles_floors_set_input
    "filter the rows which have to be updated"
    where: lht_triangles_floors_bool_exp!
}

"append existing jsonb value of filtered columns with new jsonb value"
input lht_triangles_transforms_append_input {
    value: jsonb
}

"Boolean expression to filter rows from the table \"lht_triangles.transforms\". All fields are combined with a logical 'AND'."
input lht_triangles_transforms_bool_exp {
    _and: [lht_triangles_transforms_bool_exp!]
    _not: lht_triangles_transforms_bool_exp
    _or: [lht_triangles_transforms_bool_exp!]
    name: String_comparison_exp
    value: jsonb_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input lht_triangles_transforms_delete_at_path_input {
    value: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input lht_triangles_transforms_delete_elem_input {
    value: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input lht_triangles_transforms_delete_key_input {
    value: String
}

"input type for inserting data into table \"lht_triangles.transforms\""
input lht_triangles_transforms_insert_input {
    name: String
    value: jsonb
}

"input type for inserting object relation for remote table \"lht_triangles.transforms\""
input lht_triangles_transforms_obj_rel_insert_input {
    data: lht_triangles_transforms_insert_input!
    "upsert condition"
    on_conflict: lht_triangles_transforms_on_conflict
}

"on_conflict condition type for table \"lht_triangles.transforms\""
input lht_triangles_transforms_on_conflict {
    constraint: lht_triangles_transforms_constraint!
    update_columns: [lht_triangles_transforms_update_column!]! = []
    where: lht_triangles_transforms_bool_exp
}

"Ordering options when selecting data from \"lht_triangles.transforms\"."
input lht_triangles_transforms_order_by {
    name: order_by
    value: order_by
}

"primary key columns input for table: lht_triangles.transforms"
input lht_triangles_transforms_pk_columns_input {
    name: String!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input lht_triangles_transforms_prepend_input {
    value: jsonb
}

"input type for updating data in table \"lht_triangles.transforms\""
input lht_triangles_transforms_set_input {
    name: String
    value: jsonb
}

"Streaming cursor of the table \"lht_triangles_transforms\""
input lht_triangles_transforms_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_triangles_transforms_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_triangles_transforms_stream_cursor_value_input {
    name: String
    value: jsonb
}

input lht_triangles_transforms_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: lht_triangles_transforms_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: lht_triangles_transforms_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: lht_triangles_transforms_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: lht_triangles_transforms_delete_key_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: lht_triangles_transforms_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: lht_triangles_transforms_set_input
    "filter the rows which have to be updated"
    where: lht_triangles_transforms_bool_exp!
}

input mfb_params_base_points_aggregate_bool_exp {
    count: mfb_params_base_points_aggregate_bool_exp_count
}

input mfb_params_base_points_aggregate_bool_exp_count {
    arguments: [mfb_params_base_points_select_column!]
    distinct: Boolean
    filter: mfb_params_base_points_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"mfb_params.base_points\""
input mfb_params_base_points_aggregate_order_by {
    avg: mfb_params_base_points_avg_order_by
    count: order_by
    max: mfb_params_base_points_max_order_by
    min: mfb_params_base_points_min_order_by
    stddev: mfb_params_base_points_stddev_order_by
    stddev_pop: mfb_params_base_points_stddev_pop_order_by
    stddev_samp: mfb_params_base_points_stddev_samp_order_by
    sum: mfb_params_base_points_sum_order_by
    var_pop: mfb_params_base_points_var_pop_order_by
    var_samp: mfb_params_base_points_var_samp_order_by
    variance: mfb_params_base_points_variance_order_by
}

"input type for inserting array relation for remote table \"mfb_params.base_points\""
input mfb_params_base_points_arr_rel_insert_input {
    data: [mfb_params_base_points_insert_input!]!
    "upsert condition"
    on_conflict: mfb_params_base_points_on_conflict
}

"order by avg() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_avg_order_by {
    id: order_by
    x: order_by
    y: order_by
    z: order_by
}

"Boolean expression to filter rows from the table \"mfb_params.base_points\". All fields are combined with a logical 'AND'."
input mfb_params_base_points_bool_exp {
    _and: [mfb_params_base_points_bool_exp!]
    _not: mfb_params_base_points_bool_exp
    _or: [mfb_params_base_points_bool_exp!]
    id: Int_comparison_exp
    name: String_comparison_exp
    part: mfb_params_parts_bool_exp
    part_name: mfb_params_parts_enum_comparison_exp
    update_at: timestamp_comparison_exp
    x: numeric_comparison_exp
    y: numeric_comparison_exp
    z: numeric_comparison_exp
}

"input type for incrementing numeric columns in table \"mfb_params.base_points\""
input mfb_params_base_points_inc_input {
    id: Int
    x: numeric
    y: numeric
    z: numeric
}

"input type for inserting data into table \"mfb_params.base_points\""
input mfb_params_base_points_insert_input {
    id: Int
    name: String
    part: mfb_params_parts_obj_rel_insert_input
    part_name: mfb_params_parts_enum
    update_at: timestamp
    x: numeric
    y: numeric
    z: numeric
}

"order by max() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_max_order_by {
    id: order_by
    name: order_by
    update_at: order_by
    x: order_by
    y: order_by
    z: order_by
}

"order by min() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_min_order_by {
    id: order_by
    name: order_by
    update_at: order_by
    x: order_by
    y: order_by
    z: order_by
}

"on_conflict condition type for table \"mfb_params.base_points\""
input mfb_params_base_points_on_conflict {
    constraint: mfb_params_base_points_constraint!
    update_columns: [mfb_params_base_points_update_column!]! = []
    where: mfb_params_base_points_bool_exp
}

"Ordering options when selecting data from \"mfb_params.base_points\"."
input mfb_params_base_points_order_by {
    id: order_by
    name: order_by
    part: mfb_params_parts_order_by
    part_name: order_by
    update_at: order_by
    x: order_by
    y: order_by
    z: order_by
}

"primary key columns input for table: mfb_params.base_points"
input mfb_params_base_points_pk_columns_input {
    name: String!
    part_name: mfb_params_parts_enum!
}

"input type for updating data in table \"mfb_params.base_points\""
input mfb_params_base_points_set_input {
    id: Int
    name: String
    part_name: mfb_params_parts_enum
    update_at: timestamp
    x: numeric
    y: numeric
    z: numeric
}

"order by stddev() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_stddev_order_by {
    id: order_by
    x: order_by
    y: order_by
    z: order_by
}

"order by stddev_pop() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_stddev_pop_order_by {
    id: order_by
    x: order_by
    y: order_by
    z: order_by
}

"order by stddev_samp() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_stddev_samp_order_by {
    id: order_by
    x: order_by
    y: order_by
    z: order_by
}

"Streaming cursor of the table \"mfb_params_base_points\""
input mfb_params_base_points_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: mfb_params_base_points_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input mfb_params_base_points_stream_cursor_value_input {
    id: Int
    name: String
    part_name: mfb_params_parts_enum
    update_at: timestamp
    x: numeric
    y: numeric
    z: numeric
}

"order by sum() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_sum_order_by {
    id: order_by
    x: order_by
    y: order_by
    z: order_by
}

input mfb_params_base_points_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: mfb_params_base_points_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: mfb_params_base_points_set_input
    "filter the rows which have to be updated"
    where: mfb_params_base_points_bool_exp!
}

"order by var_pop() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_var_pop_order_by {
    id: order_by
    x: order_by
    y: order_by
    z: order_by
}

"order by var_samp() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_var_samp_order_by {
    id: order_by
    x: order_by
    y: order_by
    z: order_by
}

"order by variance() on columns of table \"mfb_params.base_points\""
input mfb_params_base_points_variance_order_by {
    id: order_by
    x: order_by
    y: order_by
    z: order_by
}

"Boolean expression to filter rows from the table \"mfb_params.parts\". All fields are combined with a logical 'AND'."
input mfb_params_parts_bool_exp {
    _and: [mfb_params_parts_bool_exp!]
    _not: mfb_params_parts_bool_exp
    _or: [mfb_params_parts_bool_exp!]
    base_points: mfb_params_base_points_bool_exp
    base_points_aggregate: mfb_params_base_points_aggregate_bool_exp
    comment: String_comparison_exp
    name: String_comparison_exp
}

"Boolean expression to compare columns of type \"mfb_params_parts_enum\". All fields are combined with logical 'AND'."
input mfb_params_parts_enum_comparison_exp {
    _eq: mfb_params_parts_enum
    _in: [mfb_params_parts_enum!]
    _is_null: Boolean
    _neq: mfb_params_parts_enum
    _nin: [mfb_params_parts_enum!]
}

"input type for inserting data into table \"mfb_params.parts\""
input mfb_params_parts_insert_input {
    base_points: mfb_params_base_points_arr_rel_insert_input
    comment: String
    name: String
}

"input type for inserting object relation for remote table \"mfb_params.parts\""
input mfb_params_parts_obj_rel_insert_input {
    data: mfb_params_parts_insert_input!
    "upsert condition"
    on_conflict: mfb_params_parts_on_conflict
}

"on_conflict condition type for table \"mfb_params.parts\""
input mfb_params_parts_on_conflict {
    constraint: mfb_params_parts_constraint!
    update_columns: [mfb_params_parts_update_column!]! = []
    where: mfb_params_parts_bool_exp
}

"Ordering options when selecting data from \"mfb_params.parts\"."
input mfb_params_parts_order_by {
    base_points_aggregate: mfb_params_base_points_aggregate_order_by
    comment: order_by
    name: order_by
}

"primary key columns input for table: mfb_params.parts"
input mfb_params_parts_pk_columns_input {
    name: String!
}

"input type for updating data in table \"mfb_params.parts\""
input mfb_params_parts_set_input {
    comment: String
    name: String
}

"Streaming cursor of the table \"mfb_params_parts\""
input mfb_params_parts_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: mfb_params_parts_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input mfb_params_parts_stream_cursor_value_input {
    comment: String
    name: String
}

input mfb_params_parts_updates {
    "sets the columns of the filtered rows to the given values"
    _set: mfb_params_parts_set_input
    "filter the rows which have to be updated"
    where: mfb_params_parts_bool_exp!
}

"Boolean expression to compare columns of type \"name\". All fields are combined with logical 'AND'."
input name_comparison_exp {
    _eq: name
    _gt: name
    _gte: name
    _in: [name!]
    _is_null: Boolean
    _lt: name
    _lte: name
    _neq: name
    _nin: [name!]
}

"Boolean expression to compare columns of type \"numeric\". All fields are combined with logical 'AND'."
input numeric_comparison_exp {
    _eq: numeric
    _gt: numeric
    _gte: numeric
    _in: [numeric!]
    _is_null: Boolean
    _lt: numeric
    _lte: numeric
    _neq: numeric
    _nin: [numeric!]
}

input objects_hub_aggregate_bool_exp {
    count: objects_hub_aggregate_bool_exp_count
}

input objects_hub_aggregate_bool_exp_count {
    arguments: [objects_hub_select_column!]
    distinct: Boolean
    filter: objects_hub_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"objects_hub\""
input objects_hub_aggregate_order_by {
    count: order_by
    max: objects_hub_max_order_by
    min: objects_hub_min_order_by
}

"input type for inserting array relation for remote table \"objects_hub\""
input objects_hub_arr_rel_insert_input {
    data: [objects_hub_insert_input!]!
    "upsert condition"
    on_conflict: objects_hub_on_conflict
}

"Boolean expression to filter rows from the table \"objects_hub\". All fields are combined with a logical 'AND'."
input objects_hub_bool_exp {
    _and: [objects_hub_bool_exp!]
    _not: objects_hub_bool_exp
    _or: [objects_hub_bool_exp!]
    children: oidvector_comparison_exp
    name: String_comparison_exp
    type: String_comparison_exp
    type_relay: threejs_types_bool_exp
    uuid: uuid_comparison_exp
}

"input type for inserting data into table \"objects_hub\""
input objects_hub_insert_input {
    children: oidvector
    name: String
    type: String
    type_relay: threejs_types_obj_rel_insert_input
    uuid: uuid
}

"order by max() on columns of table \"objects_hub\""
input objects_hub_max_order_by {
    name: order_by
    type: order_by
    uuid: order_by
}

"order by min() on columns of table \"objects_hub\""
input objects_hub_min_order_by {
    name: order_by
    type: order_by
    uuid: order_by
}

"on_conflict condition type for table \"objects_hub\""
input objects_hub_on_conflict {
    constraint: objects_hub_constraint!
    update_columns: [objects_hub_update_column!]! = []
    where: objects_hub_bool_exp
}

"Ordering options when selecting data from \"objects_hub\"."
input objects_hub_order_by {
    children: order_by
    name: order_by
    type: order_by
    type_relay: threejs_types_order_by
    uuid: order_by
}

"primary key columns input for table: objects_hub"
input objects_hub_pk_columns_input {
    uuid: uuid!
}

"input type for updating data in table \"objects_hub\""
input objects_hub_set_input {
    children: oidvector
    name: String
    type: String
    uuid: uuid
}

"Streaming cursor of the table \"objects_hub\""
input objects_hub_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: objects_hub_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input objects_hub_stream_cursor_value_input {
    children: oidvector
    name: String
    type: String
    uuid: uuid
}

input objects_hub_updates {
    "sets the columns of the filtered rows to the given values"
    _set: objects_hub_set_input
    "filter the rows which have to be updated"
    where: objects_hub_bool_exp!
}

"Boolean expression to compare columns of type \"oidvector\". All fields are combined with logical 'AND'."
input oidvector_comparison_exp {
    _eq: oidvector
    _gt: oidvector
    _gte: oidvector
    _in: [oidvector!]
    _is_null: Boolean
    _lt: oidvector
    _lte: oidvector
    _neq: oidvector
    _nin: [oidvector!]
}

"Boolean expression to filter rows from the table \"platform.hosts\". All fields are combined with a logical 'AND'."
input platform_hosts_bool_exp {
    _and: [platform_hosts_bool_exp!]
    _not: platform_hosts_bool_exp
    _or: [platform_hosts_bool_exp!]
    address: String_comparison_exp
    name: String_comparison_exp
    services: platform_services_bool_exp
    services_aggregate: platform_services_aggregate_bool_exp
}

"Boolean expression to compare columns of type \"platform_hosts_enum\". All fields are combined with logical 'AND'."
input platform_hosts_enum_comparison_exp {
    _eq: platform_hosts_enum
    _in: [platform_hosts_enum!]
    _is_null: Boolean
    _neq: platform_hosts_enum
    _nin: [platform_hosts_enum!]
}

"input type for inserting data into table \"platform.hosts\""
input platform_hosts_insert_input {
    address: String
    name: String
    services: platform_services_arr_rel_insert_input
}

"input type for inserting object relation for remote table \"platform.hosts\""
input platform_hosts_obj_rel_insert_input {
    data: platform_hosts_insert_input!
    "upsert condition"
    on_conflict: platform_hosts_on_conflict
}

"on_conflict condition type for table \"platform.hosts\""
input platform_hosts_on_conflict {
    constraint: platform_hosts_constraint!
    update_columns: [platform_hosts_update_column!]! = []
    where: platform_hosts_bool_exp
}

"Ordering options when selecting data from \"platform.hosts\"."
input platform_hosts_order_by {
    address: order_by
    name: order_by
    services_aggregate: platform_services_aggregate_order_by
}

"primary key columns input for table: platform.hosts"
input platform_hosts_pk_columns_input {
    name: String!
}

"input type for updating data in table \"platform.hosts\""
input platform_hosts_set_input {
    address: String
    name: String
}

"Streaming cursor of the table \"platform_hosts\""
input platform_hosts_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: platform_hosts_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input platform_hosts_stream_cursor_value_input {
    address: String
    name: String
}

input platform_hosts_updates {
    "sets the columns of the filtered rows to the given values"
    _set: platform_hosts_set_input
    "filter the rows which have to be updated"
    where: platform_hosts_bool_exp!
}

input platform_service_attributes_aggregate_bool_exp {
    count: platform_service_attributes_aggregate_bool_exp_count
}

input platform_service_attributes_aggregate_bool_exp_count {
    arguments: [platform_service_attributes_select_column!]
    distinct: Boolean
    filter: platform_service_attributes_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"platform.service_attributes\""
input platform_service_attributes_aggregate_order_by {
    avg: platform_service_attributes_avg_order_by
    count: order_by
    max: platform_service_attributes_max_order_by
    min: platform_service_attributes_min_order_by
    stddev: platform_service_attributes_stddev_order_by
    stddev_pop: platform_service_attributes_stddev_pop_order_by
    stddev_samp: platform_service_attributes_stddev_samp_order_by
    sum: platform_service_attributes_sum_order_by
    var_pop: platform_service_attributes_var_pop_order_by
    var_samp: platform_service_attributes_var_samp_order_by
    variance: platform_service_attributes_variance_order_by
}

"input type for inserting array relation for remote table \"platform.service_attributes\""
input platform_service_attributes_arr_rel_insert_input {
    data: [platform_service_attributes_insert_input!]!
    "upsert condition"
    on_conflict: platform_service_attributes_on_conflict
}

"order by avg() on columns of table \"platform.service_attributes\""
input platform_service_attributes_avg_order_by {
    port: order_by
}

"Boolean expression to filter rows from the table \"platform.service_attributes\". All fields are combined with a logical 'AND'."
input platform_service_attributes_bool_exp {
    _and: [platform_service_attributes_bool_exp!]
    _not: platform_service_attributes_bool_exp
    _or: [platform_service_attributes_bool_exp!]
    endpoints: platform_services_bool_exp
    endpoints_aggregate: platform_services_aggregate_bool_exp
    name: platform_service_enum_comparison_exp
    port: Int_comparison_exp
    service: platform_service_bool_exp
    url: String_comparison_exp
}

"input type for incrementing numeric columns in table \"platform.service_attributes\""
input platform_service_attributes_inc_input {
    port: Int
}

"input type for inserting data into table \"platform.service_attributes\""
input platform_service_attributes_insert_input {
    endpoints: platform_services_arr_rel_insert_input
    name: platform_service_enum
    port: Int
    service: platform_service_obj_rel_insert_input
    url: String
}

"order by max() on columns of table \"platform.service_attributes\""
input platform_service_attributes_max_order_by {
    port: order_by
    url: order_by
}

"order by min() on columns of table \"platform.service_attributes\""
input platform_service_attributes_min_order_by {
    port: order_by
    url: order_by
}

"input type for inserting object relation for remote table \"platform.service_attributes\""
input platform_service_attributes_obj_rel_insert_input {
    data: platform_service_attributes_insert_input!
    "upsert condition"
    on_conflict: platform_service_attributes_on_conflict
}

"on_conflict condition type for table \"platform.service_attributes\""
input platform_service_attributes_on_conflict {
    constraint: platform_service_attributes_constraint!
    update_columns: [platform_service_attributes_update_column!]! = []
    where: platform_service_attributes_bool_exp
}

"Ordering options when selecting data from \"platform.service_attributes\"."
input platform_service_attributes_order_by {
    endpoints_aggregate: platform_services_aggregate_order_by
    name: order_by
    port: order_by
    service: platform_service_order_by
    url: order_by
}

"primary key columns input for table: platform.service_attributes"
input platform_service_attributes_pk_columns_input {
    port: Int!
}

"input type for updating data in table \"platform.service_attributes\""
input platform_service_attributes_set_input {
    name: platform_service_enum
    port: Int
    url: String
}

"order by stddev() on columns of table \"platform.service_attributes\""
input platform_service_attributes_stddev_order_by {
    port: order_by
}

"order by stddev_pop() on columns of table \"platform.service_attributes\""
input platform_service_attributes_stddev_pop_order_by {
    port: order_by
}

"order by stddev_samp() on columns of table \"platform.service_attributes\""
input platform_service_attributes_stddev_samp_order_by {
    port: order_by
}

"Streaming cursor of the table \"platform_service_attributes\""
input platform_service_attributes_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: platform_service_attributes_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input platform_service_attributes_stream_cursor_value_input {
    name: platform_service_enum
    port: Int
    url: String
}

"order by sum() on columns of table \"platform.service_attributes\""
input platform_service_attributes_sum_order_by {
    port: order_by
}

input platform_service_attributes_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: platform_service_attributes_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: platform_service_attributes_set_input
    "filter the rows which have to be updated"
    where: platform_service_attributes_bool_exp!
}

"order by var_pop() on columns of table \"platform.service_attributes\""
input platform_service_attributes_var_pop_order_by {
    port: order_by
}

"order by var_samp() on columns of table \"platform.service_attributes\""
input platform_service_attributes_var_samp_order_by {
    port: order_by
}

"order by variance() on columns of table \"platform.service_attributes\""
input platform_service_attributes_variance_order_by {
    port: order_by
}

"Boolean expression to filter rows from the table \"platform.service\". All fields are combined with a logical 'AND'."
input platform_service_bool_exp {
    _and: [platform_service_bool_exp!]
    _not: platform_service_bool_exp
    _or: [platform_service_bool_exp!]
    attributes: platform_service_attributes_bool_exp
    hosts: platform_services_bool_exp
    hosts_aggregate: platform_services_aggregate_bool_exp
    subscribes: platform_subscribes_bool_exp
    subscribes_aggregate: platform_subscribes_aggregate_bool_exp
    value: String_comparison_exp
}

"Boolean expression to compare columns of type \"platform_service_enum\". All fields are combined with logical 'AND'."
input platform_service_enum_comparison_exp {
    _eq: platform_service_enum
    _in: [platform_service_enum!]
    _is_null: Boolean
    _neq: platform_service_enum
    _nin: [platform_service_enum!]
}

"input type for inserting data into table \"platform.service\""
input platform_service_insert_input {
    attributes: platform_service_attributes_obj_rel_insert_input
    hosts: platform_services_arr_rel_insert_input
    subscribes: platform_subscribes_arr_rel_insert_input
    value: String
}

"input type for inserting object relation for remote table \"platform.service\""
input platform_service_obj_rel_insert_input {
    data: platform_service_insert_input!
    "upsert condition"
    on_conflict: platform_service_on_conflict
}

"on_conflict condition type for table \"platform.service\""
input platform_service_on_conflict {
    constraint: platform_service_constraint!
    update_columns: [platform_service_update_column!]! = []
    where: platform_service_bool_exp
}

"Ordering options when selecting data from \"platform.service\"."
input platform_service_order_by {
    attributes: platform_service_attributes_order_by
    hosts_aggregate: platform_services_aggregate_order_by
    subscribes_aggregate: platform_subscribes_aggregate_order_by
    value: order_by
}

"primary key columns input for table: platform.service"
input platform_service_pk_columns_input {
    value: String!
}

"input type for updating data in table \"platform.service\""
input platform_service_set_input {
    value: String
}

"Streaming cursor of the table \"platform_service\""
input platform_service_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: platform_service_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input platform_service_stream_cursor_value_input {
    value: String
}

input platform_service_updates {
    "sets the columns of the filtered rows to the given values"
    _set: platform_service_set_input
    "filter the rows which have to be updated"
    where: platform_service_bool_exp!
}

input platform_services_aggregate_bool_exp {
    count: platform_services_aggregate_bool_exp_count
}

input platform_services_aggregate_bool_exp_count {
    arguments: [platform_services_select_column!]
    distinct: Boolean
    filter: platform_services_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"platform.services\""
input platform_services_aggregate_order_by {
    count: order_by
    max: platform_services_max_order_by
    min: platform_services_min_order_by
}

"input type for inserting array relation for remote table \"platform.services\""
input platform_services_arr_rel_insert_input {
    data: [platform_services_insert_input!]!
}

"Boolean expression to filter rows from the table \"platform.services\". All fields are combined with a logical 'AND'."
input platform_services_bool_exp {
    _and: [platform_services_bool_exp!]
    _not: platform_services_bool_exp
    _or: [platform_services_bool_exp!]
    created_at: timestamptz_comparison_exp
    host: platform_hosts_bool_exp
    host_name: platform_hosts_enum_comparison_exp
    service: platform_service_bool_exp
    service_name: platform_service_enum_comparison_exp
}

"input type for inserting data into table \"platform.services\""
input platform_services_insert_input {
    created_at: timestamptz
    host: platform_hosts_obj_rel_insert_input
    host_name: platform_hosts_enum
    service: platform_service_obj_rel_insert_input
    service_name: platform_service_enum
}

"order by max() on columns of table \"platform.services\""
input platform_services_max_order_by {
    created_at: order_by
}

"order by min() on columns of table \"platform.services\""
input platform_services_min_order_by {
    created_at: order_by
}

"Ordering options when selecting data from \"platform.services\"."
input platform_services_order_by {
    created_at: order_by
    host: platform_hosts_order_by
    host_name: order_by
    service: platform_service_order_by
    service_name: order_by
}

"input type for updating data in table \"platform.services\""
input platform_services_set_input {
    created_at: timestamptz
    host_name: platform_hosts_enum
    service_name: platform_service_enum
}

"Streaming cursor of the table \"platform_services\""
input platform_services_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: platform_services_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input platform_services_stream_cursor_value_input {
    created_at: timestamptz
    host_name: platform_hosts_enum
    service_name: platform_service_enum
}

input platform_services_updates {
    "sets the columns of the filtered rows to the given values"
    _set: platform_services_set_input
    "filter the rows which have to be updated"
    where: platform_services_bool_exp!
}

input platform_subscribes_aggregate_bool_exp {
    count: platform_subscribes_aggregate_bool_exp_count
}

input platform_subscribes_aggregate_bool_exp_count {
    arguments: [platform_subscribes_select_column!]
    distinct: Boolean
    filter: platform_subscribes_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"platform.subscribes\""
input platform_subscribes_aggregate_order_by {
    avg: platform_subscribes_avg_order_by
    count: order_by
    max: platform_subscribes_max_order_by
    min: platform_subscribes_min_order_by
    stddev: platform_subscribes_stddev_order_by
    stddev_pop: platform_subscribes_stddev_pop_order_by
    stddev_samp: platform_subscribes_stddev_samp_order_by
    sum: platform_subscribes_sum_order_by
    var_pop: platform_subscribes_var_pop_order_by
    var_samp: platform_subscribes_var_samp_order_by
    variance: platform_subscribes_variance_order_by
}

"input type for inserting array relation for remote table \"platform.subscribes\""
input platform_subscribes_arr_rel_insert_input {
    data: [platform_subscribes_insert_input!]!
    "upsert condition"
    on_conflict: platform_subscribes_on_conflict
}

"order by avg() on columns of table \"platform.subscribes\""
input platform_subscribes_avg_order_by {
    id: order_by
}

"Boolean expression to filter rows from the table \"platform.subscribes\". All fields are combined with a logical 'AND'."
input platform_subscribes_bool_exp {
    _and: [platform_subscribes_bool_exp!]
    _not: platform_subscribes_bool_exp
    _or: [platform_subscribes_bool_exp!]
    id: Int_comparison_exp
    service: platform_service_enum_comparison_exp
    serviceByTopic: platform_service_bool_exp
    topic: platform_topics_enum_comparison_exp
    topicByService: platform_topics_bool_exp
}

"input type for incrementing numeric columns in table \"platform.subscribes\""
input platform_subscribes_inc_input {
    id: Int
}

"input type for inserting data into table \"platform.subscribes\""
input platform_subscribes_insert_input {
    id: Int
    service: platform_service_enum
    serviceByTopic: platform_service_obj_rel_insert_input
    topic: platform_topics_enum
    topicByService: platform_topics_obj_rel_insert_input
}

"order by max() on columns of table \"platform.subscribes\""
input platform_subscribes_max_order_by {
    id: order_by
}

"order by min() on columns of table \"platform.subscribes\""
input platform_subscribes_min_order_by {
    id: order_by
}

"on_conflict condition type for table \"platform.subscribes\""
input platform_subscribes_on_conflict {
    constraint: platform_subscribes_constraint!
    update_columns: [platform_subscribes_update_column!]! = []
    where: platform_subscribes_bool_exp
}

"Ordering options when selecting data from \"platform.subscribes\"."
input platform_subscribes_order_by {
    id: order_by
    service: order_by
    serviceByTopic: platform_service_order_by
    topic: order_by
    topicByService: platform_topics_order_by
}

"primary key columns input for table: platform.subscribes"
input platform_subscribes_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"platform.subscribes\""
input platform_subscribes_set_input {
    id: Int
    service: platform_service_enum
    topic: platform_topics_enum
}

"order by stddev() on columns of table \"platform.subscribes\""
input platform_subscribes_stddev_order_by {
    id: order_by
}

"order by stddev_pop() on columns of table \"platform.subscribes\""
input platform_subscribes_stddev_pop_order_by {
    id: order_by
}

"order by stddev_samp() on columns of table \"platform.subscribes\""
input platform_subscribes_stddev_samp_order_by {
    id: order_by
}

"Streaming cursor of the table \"platform_subscribes\""
input platform_subscribes_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: platform_subscribes_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input platform_subscribes_stream_cursor_value_input {
    id: Int
    service: platform_service_enum
    topic: platform_topics_enum
}

"order by sum() on columns of table \"platform.subscribes\""
input platform_subscribes_sum_order_by {
    id: order_by
}

input platform_subscribes_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: platform_subscribes_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: platform_subscribes_set_input
    "filter the rows which have to be updated"
    where: platform_subscribes_bool_exp!
}

"order by var_pop() on columns of table \"platform.subscribes\""
input platform_subscribes_var_pop_order_by {
    id: order_by
}

"order by var_samp() on columns of table \"platform.subscribes\""
input platform_subscribes_var_samp_order_by {
    id: order_by
}

"order by variance() on columns of table \"platform.subscribes\""
input platform_subscribes_variance_order_by {
    id: order_by
}

"Boolean expression to filter rows from the table \"platform.topics\". All fields are combined with a logical 'AND'."
input platform_topics_bool_exp {
    _and: [platform_topics_bool_exp!]
    _not: platform_topics_bool_exp
    _or: [platform_topics_bool_exp!]
    services: platform_service_attributes_bool_exp
    services_aggregate: platform_service_attributes_aggregate_bool_exp
    subscribes: platform_subscribes_bool_exp
    subscribes_aggregate: platform_subscribes_aggregate_bool_exp
    value: String_comparison_exp
}

"Boolean expression to compare columns of type \"platform_topics_enum\". All fields are combined with logical 'AND'."
input platform_topics_enum_comparison_exp {
    _eq: platform_topics_enum
    _in: [platform_topics_enum!]
    _is_null: Boolean
    _neq: platform_topics_enum
    _nin: [platform_topics_enum!]
}

"input type for inserting data into table \"platform.topics\""
input platform_topics_insert_input {
    services: platform_service_attributes_arr_rel_insert_input
    subscribes: platform_subscribes_arr_rel_insert_input
    value: String
}

"input type for inserting object relation for remote table \"platform.topics\""
input platform_topics_obj_rel_insert_input {
    data: platform_topics_insert_input!
    "upsert condition"
    on_conflict: platform_topics_on_conflict
}

"on_conflict condition type for table \"platform.topics\""
input platform_topics_on_conflict {
    constraint: platform_topics_constraint!
    update_columns: [platform_topics_update_column!]! = []
    where: platform_topics_bool_exp
}

"Ordering options when selecting data from \"platform.topics\"."
input platform_topics_order_by {
    services_aggregate: platform_service_attributes_aggregate_order_by
    subscribes_aggregate: platform_subscribes_aggregate_order_by
    value: order_by
}

"primary key columns input for table: platform.topics"
input platform_topics_pk_columns_input {
    value: String!
}

"input type for updating data in table \"platform.topics\""
input platform_topics_set_input {
    value: String
}

"Streaming cursor of the table \"platform_topics\""
input platform_topics_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: platform_topics_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input platform_topics_stream_cursor_value_input {
    value: String
}

input platform_topics_updates {
    "sets the columns of the filtered rows to the given values"
    _set: platform_topics_set_input
    "filter the rows which have to be updated"
    where: platform_topics_bool_exp!
}

"Boolean expression to filter rows from the table \"survey.ceiling\". All fields are combined with a logical 'AND'."
input survey_ceiling_bool_exp {
    _and: [survey_ceiling_bool_exp!]
    _not: survey_ceiling_bool_exp
    _or: [survey_ceiling_bool_exp!]
    floor: lht_triangles_floors_bool_exp
    floor_name: String_comparison_exp
    id: Int_comparison_exp
    index: Int_comparison_exp
    tag: String_comparison_exp
    transform: lht_triangles_transforms_bool_exp
    transform_name: String_comparison_exp
    update_at: timestamp_comparison_exp
    x: float8_comparison_exp
    y: float8_comparison_exp
    z: float8_comparison_exp
}

"input type for incrementing numeric columns in table \"survey.ceiling\""
input survey_ceiling_inc_input {
    "geodesist index"
    index: Int
    x: float8
    y: float8
    z: float8
}

"input type for inserting data into table \"survey.ceiling\""
input survey_ceiling_insert_input {
    floor: lht_triangles_floors_obj_rel_insert_input
    floor_name: String
    "geodesist index"
    index: Int
    tag: String
    transform: lht_triangles_transforms_obj_rel_insert_input
    transform_name: String
    update_at: timestamp
    x: float8
    y: float8
    z: float8
}

"on_conflict condition type for table \"survey.ceiling\""
input survey_ceiling_on_conflict {
    constraint: survey_ceiling_constraint!
    update_columns: [survey_ceiling_update_column!]! = []
    where: survey_ceiling_bool_exp
}

"Ordering options when selecting data from \"survey.ceiling\"."
input survey_ceiling_order_by {
    floor: lht_triangles_floors_order_by
    floor_name: order_by
    id: order_by
    index: order_by
    tag: order_by
    transform: lht_triangles_transforms_order_by
    transform_name: order_by
    update_at: order_by
    x: order_by
    y: order_by
    z: order_by
}

"primary key columns input for table: survey.ceiling"
input survey_ceiling_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"survey.ceiling\""
input survey_ceiling_set_input {
    floor_name: String
    "geodesist index"
    index: Int
    tag: String
    transform_name: String
    update_at: timestamp
    x: float8
    y: float8
    z: float8
}

"Streaming cursor of the table \"survey_ceiling\""
input survey_ceiling_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: survey_ceiling_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input survey_ceiling_stream_cursor_value_input {
    floor_name: String
    id: Int
    "geodesist index"
    index: Int
    tag: String
    transform_name: String
    update_at: timestamp
    x: float8
    y: float8
    z: float8
}

input survey_ceiling_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: survey_ceiling_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: survey_ceiling_set_input
    "filter the rows which have to be updated"
    where: survey_ceiling_bool_exp!
}

"Boolean expression to filter rows from the table \"threejs.types\". All fields are combined with a logical 'AND'."
input threejs_types_bool_exp {
    _and: [threejs_types_bool_exp!]
    _not: threejs_types_bool_exp
    _or: [threejs_types_bool_exp!]
    comment: String_comparison_exp
    objects: objects_hub_bool_exp
    objects_aggregate: objects_hub_aggregate_bool_exp
    value: String_comparison_exp
}

"input type for inserting data into table \"threejs.types\""
input threejs_types_insert_input {
    comment: String
    objects: objects_hub_arr_rel_insert_input
    value: String
}

"input type for inserting object relation for remote table \"threejs.types\""
input threejs_types_obj_rel_insert_input {
    data: threejs_types_insert_input!
    "upsert condition"
    on_conflict: threejs_types_on_conflict
}

"on_conflict condition type for table \"threejs.types\""
input threejs_types_on_conflict {
    constraint: threejs_types_constraint!
    update_columns: [threejs_types_update_column!]! = []
    where: threejs_types_bool_exp
}

"Ordering options when selecting data from \"threejs.types\"."
input threejs_types_order_by {
    comment: order_by
    objects_aggregate: objects_hub_aggregate_order_by
    value: order_by
}

"primary key columns input for table: threejs.types"
input threejs_types_pk_columns_input {
    value: String!
}

"input type for updating data in table \"threejs.types\""
input threejs_types_set_input {
    comment: String
    value: String
}

"Streaming cursor of the table \"threejs_types\""
input threejs_types_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: threejs_types_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input threejs_types_stream_cursor_value_input {
    comment: String
    value: String
}

input threejs_types_updates {
    "sets the columns of the filtered rows to the given values"
    _set: threejs_types_set_input
    "filter the rows which have to be updated"
    where: threejs_types_bool_exp!
}

"Boolean expression to compare columns of type \"timestamp\". All fields are combined with logical 'AND'."
input timestamp_comparison_exp {
    _eq: timestamp
    _gt: timestamp
    _gte: timestamp
    _in: [timestamp!]
    _is_null: Boolean
    _lt: timestamp
    _lte: timestamp
    _neq: timestamp
    _nin: [timestamp!]
}

"Boolean expression to compare columns of type \"timestamptz\". All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
    _eq: timestamptz
    _gt: timestamptz
    _gte: timestamptz
    _in: [timestamptz!]
    _is_null: Boolean
    _lt: timestamptz
    _lte: timestamptz
    _neq: timestamptz
    _nin: [timestamptz!]
}

"Boolean expression to compare columns of type \"uuid\". All fields are combined with logical 'AND'."
input uuid_comparison_exp {
    _eq: uuid
    _gt: uuid
    _gte: uuid
    _in: [uuid!]
    _is_null: Boolean
    _lt: uuid
    _lte: uuid
    _neq: uuid
    _nin: [uuid!]
}
